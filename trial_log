DEBUG - Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG - https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-cased-vocab.txt HTTP/1.1" 200 0
INFO - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /root/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
INFO - loading configuration file ../biobert_v1.1_pubmed/config.json
INFO - Model config BertConfig {
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": true,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO - loading weights file ../biobert_v1.1_pubmed/model.ckpt.index
INFO - Converting TensorFlow checkpoint from /bioasq/biobert_v1.1_pubmed/model.ckpt
INFO - Loading TF weight bert/embeddings/LayerNorm/beta with shape [768]
INFO - Loading TF weight bert/embeddings/LayerNorm/gamma with shape [768]
INFO - Loading TF weight bert/embeddings/position_embeddings with shape [512, 768]
INFO - Loading TF weight bert/embeddings/token_type_embeddings with shape [2, 768]
INFO - Loading TF weight bert/embeddings/word_embeddings with shape [28996, 768]
INFO - Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/beta with shape [768]
INFO - Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/gamma with shape [768]
INFO - Loading TF weight bert/encoder/layer_0/attention/output/dense/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_0/attention/output/dense/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_0/attention/self/key/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_0/attention/self/key/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_0/attention/self/query/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_0/attention/self/query/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_0/attention/self/value/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_0/attention/self/value/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_0/intermediate/dense/bias with shape [3072]
INFO - Loading TF weight bert/encoder/layer_0/intermediate/dense/kernel with shape [768, 3072]
INFO - Loading TF weight bert/encoder/layer_0/output/LayerNorm/beta with shape [768]
INFO - Loading TF weight bert/encoder/layer_0/output/LayerNorm/gamma with shape [768]
INFO - Loading TF weight bert/encoder/layer_0/output/dense/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_0/output/dense/kernel with shape [3072, 768]
INFO - Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/beta with shape [768]
INFO - Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/gamma with shape [768]
INFO - Loading TF weight bert/encoder/layer_1/attention/output/dense/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_1/attention/output/dense/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_1/attention/self/key/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_1/attention/self/key/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_1/attention/self/query/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_1/attention/self/query/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_1/attention/self/value/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_1/attention/self/value/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_1/intermediate/dense/bias with shape [3072]
INFO - Loading TF weight bert/encoder/layer_1/intermediate/dense/kernel with shape [768, 3072]
INFO - Loading TF weight bert/encoder/layer_1/output/LayerNorm/beta with shape [768]
INFO - Loading TF weight bert/encoder/layer_1/output/LayerNorm/gamma with shape [768]
INFO - Loading TF weight bert/encoder/layer_1/output/dense/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_1/output/dense/kernel with shape [3072, 768]
INFO - Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/beta with shape [768]
INFO - Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/gamma with shape [768]
INFO - Loading TF weight bert/encoder/layer_10/attention/output/dense/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_10/attention/output/dense/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_10/attention/self/key/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_10/attention/self/key/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_10/attention/self/query/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_10/attention/self/query/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_10/attention/self/value/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_10/attention/self/value/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_10/intermediate/dense/bias with shape [3072]
INFO - Loading TF weight bert/encoder/layer_10/intermediate/dense/kernel with shape [768, 3072]
INFO - Loading TF weight bert/encoder/layer_10/output/LayerNorm/beta with shape [768]
INFO - Loading TF weight bert/encoder/layer_10/output/LayerNorm/gamma with shape [768]
INFO - Loading TF weight bert/encoder/layer_10/output/dense/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_10/output/dense/kernel with shape [3072, 768]
INFO - Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/beta with shape [768]
INFO - Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/gamma with shape [768]
INFO - Loading TF weight bert/encoder/layer_11/attention/output/dense/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_11/attention/output/dense/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_11/attention/self/key/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_11/attention/self/key/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_11/attention/self/query/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_11/attention/self/query/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_11/attention/self/value/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_11/attention/self/value/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_11/intermediate/dense/bias with shape [3072]
INFO - Loading TF weight bert/encoder/layer_11/intermediate/dense/kernel with shape [768, 3072]
INFO - Loading TF weight bert/encoder/layer_11/output/LayerNorm/beta with shape [768]
INFO - Loading TF weight bert/encoder/layer_11/output/LayerNorm/gamma with shape [768]
INFO - Loading TF weight bert/encoder/layer_11/output/dense/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_11/output/dense/kernel with shape [3072, 768]
INFO - Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/beta with shape [768]
INFO - Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/gamma with shape [768]
INFO - Loading TF weight bert/encoder/layer_2/attention/output/dense/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_2/attention/output/dense/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_2/attention/self/key/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_2/attention/self/key/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_2/attention/self/query/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_2/attention/self/query/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_2/attention/self/value/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_2/attention/self/value/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_2/intermediate/dense/bias with shape [3072]
INFO - Loading TF weight bert/encoder/layer_2/intermediate/dense/kernel with shape [768, 3072]
INFO - Loading TF weight bert/encoder/layer_2/output/LayerNorm/beta with shape [768]
INFO - Loading TF weight bert/encoder/layer_2/output/LayerNorm/gamma with shape [768]
INFO - Loading TF weight bert/encoder/layer_2/output/dense/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_2/output/dense/kernel with shape [3072, 768]
INFO - Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/beta with shape [768]
INFO - Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/gamma with shape [768]
INFO - Loading TF weight bert/encoder/layer_3/attention/output/dense/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_3/attention/output/dense/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_3/attention/self/key/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_3/attention/self/key/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_3/attention/self/query/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_3/attention/self/query/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_3/attention/self/value/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_3/attention/self/value/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_3/intermediate/dense/bias with shape [3072]
INFO - Loading TF weight bert/encoder/layer_3/intermediate/dense/kernel with shape [768, 3072]
INFO - Loading TF weight bert/encoder/layer_3/output/LayerNorm/beta with shape [768]
INFO - Loading TF weight bert/encoder/layer_3/output/LayerNorm/gamma with shape [768]
INFO - Loading TF weight bert/encoder/layer_3/output/dense/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_3/output/dense/kernel with shape [3072, 768]
INFO - Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/beta with shape [768]
INFO - Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/gamma with shape [768]
INFO - Loading TF weight bert/encoder/layer_4/attention/output/dense/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_4/attention/output/dense/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_4/attention/self/key/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_4/attention/self/key/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_4/attention/self/query/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_4/attention/self/query/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_4/attention/self/value/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_4/attention/self/value/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_4/intermediate/dense/bias with shape [3072]
INFO - Loading TF weight bert/encoder/layer_4/intermediate/dense/kernel with shape [768, 3072]
INFO - Loading TF weight bert/encoder/layer_4/output/LayerNorm/beta with shape [768]
INFO - Loading TF weight bert/encoder/layer_4/output/LayerNorm/gamma with shape [768]
INFO - Loading TF weight bert/encoder/layer_4/output/dense/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_4/output/dense/kernel with shape [3072, 768]
INFO - Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/beta with shape [768]
INFO - Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/gamma with shape [768]
INFO - Loading TF weight bert/encoder/layer_5/attention/output/dense/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_5/attention/output/dense/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_5/attention/self/key/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_5/attention/self/key/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_5/attention/self/query/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_5/attention/self/query/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_5/attention/self/value/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_5/attention/self/value/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_5/intermediate/dense/bias with shape [3072]
INFO - Loading TF weight bert/encoder/layer_5/intermediate/dense/kernel with shape [768, 3072]
INFO - Loading TF weight bert/encoder/layer_5/output/LayerNorm/beta with shape [768]
INFO - Loading TF weight bert/encoder/layer_5/output/LayerNorm/gamma with shape [768]
INFO - Loading TF weight bert/encoder/layer_5/output/dense/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_5/output/dense/kernel with shape [3072, 768]
INFO - Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/beta with shape [768]
INFO - Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/gamma with shape [768]
INFO - Loading TF weight bert/encoder/layer_6/attention/output/dense/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_6/attention/output/dense/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_6/attention/self/key/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_6/attention/self/key/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_6/attention/self/query/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_6/attention/self/query/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_6/attention/self/value/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_6/attention/self/value/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_6/intermediate/dense/bias with shape [3072]
INFO - Loading TF weight bert/encoder/layer_6/intermediate/dense/kernel with shape [768, 3072]
INFO - Loading TF weight bert/encoder/layer_6/output/LayerNorm/beta with shape [768]
INFO - Loading TF weight bert/encoder/layer_6/output/LayerNorm/gamma with shape [768]
INFO - Loading TF weight bert/encoder/layer_6/output/dense/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_6/output/dense/kernel with shape [3072, 768]
INFO - Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/beta with shape [768]
INFO - Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/gamma with shape [768]
INFO - Loading TF weight bert/encoder/layer_7/attention/output/dense/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_7/attention/output/dense/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_7/attention/self/key/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_7/attention/self/key/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_7/attention/self/query/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_7/attention/self/query/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_7/attention/self/value/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_7/attention/self/value/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_7/intermediate/dense/bias with shape [3072]
INFO - Loading TF weight bert/encoder/layer_7/intermediate/dense/kernel with shape [768, 3072]
INFO - Loading TF weight bert/encoder/layer_7/output/LayerNorm/beta with shape [768]
INFO - Loading TF weight bert/encoder/layer_7/output/LayerNorm/gamma with shape [768]
INFO - Loading TF weight bert/encoder/layer_7/output/dense/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_7/output/dense/kernel with shape [3072, 768]
INFO - Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/beta with shape [768]
INFO - Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/gamma with shape [768]
INFO - Loading TF weight bert/encoder/layer_8/attention/output/dense/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_8/attention/output/dense/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_8/attention/self/key/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_8/attention/self/key/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_8/attention/self/query/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_8/attention/self/query/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_8/attention/self/value/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_8/attention/self/value/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_8/intermediate/dense/bias with shape [3072]
INFO - Loading TF weight bert/encoder/layer_8/intermediate/dense/kernel with shape [768, 3072]
INFO - Loading TF weight bert/encoder/layer_8/output/LayerNorm/beta with shape [768]
INFO - Loading TF weight bert/encoder/layer_8/output/LayerNorm/gamma with shape [768]
INFO - Loading TF weight bert/encoder/layer_8/output/dense/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_8/output/dense/kernel with shape [3072, 768]
INFO - Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/beta with shape [768]
INFO - Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/gamma with shape [768]
INFO - Loading TF weight bert/encoder/layer_9/attention/output/dense/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_9/attention/output/dense/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_9/attention/self/key/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_9/attention/self/key/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_9/attention/self/query/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_9/attention/self/query/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_9/attention/self/value/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_9/attention/self/value/kernel with shape [768, 768]
INFO - Loading TF weight bert/encoder/layer_9/intermediate/dense/bias with shape [3072]
INFO - Loading TF weight bert/encoder/layer_9/intermediate/dense/kernel with shape [768, 3072]
INFO - Loading TF weight bert/encoder/layer_9/output/LayerNorm/beta with shape [768]
INFO - Loading TF weight bert/encoder/layer_9/output/LayerNorm/gamma with shape [768]
INFO - Loading TF weight bert/encoder/layer_9/output/dense/bias with shape [768]
INFO - Loading TF weight bert/encoder/layer_9/output/dense/kernel with shape [3072, 768]
INFO - Loading TF weight bert/pooler/dense/bias with shape [768]
INFO - Loading TF weight bert/pooler/dense/kernel with shape [768, 768]
INFO - Skipping bert/embeddings/LayerNorm/beta
INFO - Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'beta']
INFO - Skipping bert/embeddings/LayerNorm/gamma
INFO - Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'gamma']
INFO - Skipping bert/embeddings/position_embeddings
INFO - Initialize PyTorch weight ['bert', 'embeddings', 'position_embeddings']
INFO - Skipping bert/embeddings/token_type_embeddings
INFO - Initialize PyTorch weight ['bert', 'embeddings', 'token_type_embeddings']
INFO - Skipping bert/embeddings/word_embeddings
INFO - Initialize PyTorch weight ['bert', 'embeddings', 'word_embeddings']
INFO - Skipping bert/encoder/layer_0/attention/output/LayerNorm/beta
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'beta']
INFO - Skipping bert/encoder/layer_0/attention/output/LayerNorm/gamma
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'gamma']
INFO - Skipping bert/encoder/layer_0/attention/output/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_0/attention/output/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'kernel']
INFO - Skipping bert/encoder/layer_0/attention/self/key/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'bias']
INFO - Skipping bert/encoder/layer_0/attention/self/key/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'kernel']
INFO - Skipping bert/encoder/layer_0/attention/self/query/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'bias']
INFO - Skipping bert/encoder/layer_0/attention/self/query/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'kernel']
INFO - Skipping bert/encoder/layer_0/attention/self/value/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'bias']
INFO - Skipping bert/encoder/layer_0/attention/self/value/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'kernel']
INFO - Skipping bert/encoder/layer_0/intermediate/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_0/intermediate/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'kernel']
INFO - Skipping bert/encoder/layer_0/output/LayerNorm/beta
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'beta']
INFO - Skipping bert/encoder/layer_0/output/LayerNorm/gamma
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'gamma']
INFO - Skipping bert/encoder/layer_0/output/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_0/output/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'kernel']
INFO - Skipping bert/encoder/layer_1/attention/output/LayerNorm/beta
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'beta']
INFO - Skipping bert/encoder/layer_1/attention/output/LayerNorm/gamma
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'gamma']
INFO - Skipping bert/encoder/layer_1/attention/output/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_1/attention/output/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'kernel']
INFO - Skipping bert/encoder/layer_1/attention/self/key/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'bias']
INFO - Skipping bert/encoder/layer_1/attention/self/key/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'kernel']
INFO - Skipping bert/encoder/layer_1/attention/self/query/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'bias']
INFO - Skipping bert/encoder/layer_1/attention/self/query/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'kernel']
INFO - Skipping bert/encoder/layer_1/attention/self/value/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'bias']
INFO - Skipping bert/encoder/layer_1/attention/self/value/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'kernel']
INFO - Skipping bert/encoder/layer_1/intermediate/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_1/intermediate/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'kernel']
INFO - Skipping bert/encoder/layer_1/output/LayerNorm/beta
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'beta']
INFO - Skipping bert/encoder/layer_1/output/LayerNorm/gamma
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'gamma']
INFO - Skipping bert/encoder/layer_1/output/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_1/output/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'kernel']
INFO - Skipping bert/encoder/layer_10/attention/output/LayerNorm/beta
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'beta']
INFO - Skipping bert/encoder/layer_10/attention/output/LayerNorm/gamma
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'gamma']
INFO - Skipping bert/encoder/layer_10/attention/output/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_10/attention/output/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'kernel']
INFO - Skipping bert/encoder/layer_10/attention/self/key/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'bias']
INFO - Skipping bert/encoder/layer_10/attention/self/key/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'kernel']
INFO - Skipping bert/encoder/layer_10/attention/self/query/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'bias']
INFO - Skipping bert/encoder/layer_10/attention/self/query/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'kernel']
INFO - Skipping bert/encoder/layer_10/attention/self/value/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'bias']
INFO - Skipping bert/encoder/layer_10/attention/self/value/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'kernel']
INFO - Skipping bert/encoder/layer_10/intermediate/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_10/intermediate/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'kernel']
INFO - Skipping bert/encoder/layer_10/output/LayerNorm/beta
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'beta']
INFO - Skipping bert/encoder/layer_10/output/LayerNorm/gamma
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'gamma']
INFO - Skipping bert/encoder/layer_10/output/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_10/output/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'kernel']
INFO - Skipping bert/encoder/layer_11/attention/output/LayerNorm/beta
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'beta']
INFO - Skipping bert/encoder/layer_11/attention/output/LayerNorm/gamma
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'gamma']
INFO - Skipping bert/encoder/layer_11/attention/output/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_11/attention/output/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'kernel']
INFO - Skipping bert/encoder/layer_11/attention/self/key/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'bias']
INFO - Skipping bert/encoder/layer_11/attention/self/key/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'kernel']
INFO - Skipping bert/encoder/layer_11/attention/self/query/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'bias']
INFO - Skipping bert/encoder/layer_11/attention/self/query/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'kernel']
INFO - Skipping bert/encoder/layer_11/attention/self/value/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'bias']
INFO - Skipping bert/encoder/layer_11/attention/self/value/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'kernel']
INFO - Skipping bert/encoder/layer_11/intermediate/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_11/intermediate/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'kernel']
INFO - Skipping bert/encoder/layer_11/output/LayerNorm/beta
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'beta']
INFO - Skipping bert/encoder/layer_11/output/LayerNorm/gamma
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'gamma']
INFO - Skipping bert/encoder/layer_11/output/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_11/output/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'kernel']
INFO - Skipping bert/encoder/layer_2/attention/output/LayerNorm/beta
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'beta']
INFO - Skipping bert/encoder/layer_2/attention/output/LayerNorm/gamma
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'gamma']
INFO - Skipping bert/encoder/layer_2/attention/output/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_2/attention/output/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'kernel']
INFO - Skipping bert/encoder/layer_2/attention/self/key/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'bias']
INFO - Skipping bert/encoder/layer_2/attention/self/key/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'kernel']
INFO - Skipping bert/encoder/layer_2/attention/self/query/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'bias']
INFO - Skipping bert/encoder/layer_2/attention/self/query/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'kernel']
INFO - Skipping bert/encoder/layer_2/attention/self/value/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'bias']
INFO - Skipping bert/encoder/layer_2/attention/self/value/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'kernel']
INFO - Skipping bert/encoder/layer_2/intermediate/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_2/intermediate/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'kernel']
INFO - Skipping bert/encoder/layer_2/output/LayerNorm/beta
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'beta']
INFO - Skipping bert/encoder/layer_2/output/LayerNorm/gamma
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'gamma']
INFO - Skipping bert/encoder/layer_2/output/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_2/output/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'kernel']
INFO - Skipping bert/encoder/layer_3/attention/output/LayerNorm/beta
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'beta']
INFO - Skipping bert/encoder/layer_3/attention/output/LayerNorm/gamma
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'gamma']
INFO - Skipping bert/encoder/layer_3/attention/output/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_3/attention/output/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'kernel']
INFO - Skipping bert/encoder/layer_3/attention/self/key/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'bias']
INFO - Skipping bert/encoder/layer_3/attention/self/key/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'kernel']
INFO - Skipping bert/encoder/layer_3/attention/self/query/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'bias']
INFO - Skipping bert/encoder/layer_3/attention/self/query/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'kernel']
INFO - Skipping bert/encoder/layer_3/attention/self/value/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'bias']
INFO - Skipping bert/encoder/layer_3/attention/self/value/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'kernel']
INFO - Skipping bert/encoder/layer_3/intermediate/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_3/intermediate/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'kernel']
INFO - Skipping bert/encoder/layer_3/output/LayerNorm/beta
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'beta']
INFO - Skipping bert/encoder/layer_3/output/LayerNorm/gamma
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'gamma']
INFO - Skipping bert/encoder/layer_3/output/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_3/output/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'kernel']
INFO - Skipping bert/encoder/layer_4/attention/output/LayerNorm/beta
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'beta']
INFO - Skipping bert/encoder/layer_4/attention/output/LayerNorm/gamma
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'gamma']
INFO - Skipping bert/encoder/layer_4/attention/output/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_4/attention/output/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'kernel']
INFO - Skipping bert/encoder/layer_4/attention/self/key/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'bias']
INFO - Skipping bert/encoder/layer_4/attention/self/key/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'kernel']
INFO - Skipping bert/encoder/layer_4/attention/self/query/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'bias']
INFO - Skipping bert/encoder/layer_4/attention/self/query/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'kernel']
INFO - Skipping bert/encoder/layer_4/attention/self/value/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'bias']
INFO - Skipping bert/encoder/layer_4/attention/self/value/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'kernel']
INFO - Skipping bert/encoder/layer_4/intermediate/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_4/intermediate/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'kernel']
INFO - Skipping bert/encoder/layer_4/output/LayerNorm/beta
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'beta']
INFO - Skipping bert/encoder/layer_4/output/LayerNorm/gamma
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'gamma']
INFO - Skipping bert/encoder/layer_4/output/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_4/output/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'kernel']
INFO - Skipping bert/encoder/layer_5/attention/output/LayerNorm/beta
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'beta']
INFO - Skipping bert/encoder/layer_5/attention/output/LayerNorm/gamma
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'gamma']
INFO - Skipping bert/encoder/layer_5/attention/output/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_5/attention/output/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'kernel']
INFO - Skipping bert/encoder/layer_5/attention/self/key/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'bias']
INFO - Skipping bert/encoder/layer_5/attention/self/key/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'kernel']
INFO - Skipping bert/encoder/layer_5/attention/self/query/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'bias']
INFO - Skipping bert/encoder/layer_5/attention/self/query/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'kernel']
INFO - Skipping bert/encoder/layer_5/attention/self/value/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'bias']
INFO - Skipping bert/encoder/layer_5/attention/self/value/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'kernel']
INFO - Skipping bert/encoder/layer_5/intermediate/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_5/intermediate/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'kernel']
INFO - Skipping bert/encoder/layer_5/output/LayerNorm/beta
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'beta']
INFO - Skipping bert/encoder/layer_5/output/LayerNorm/gamma
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'gamma']
INFO - Skipping bert/encoder/layer_5/output/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_5/output/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'kernel']
INFO - Skipping bert/encoder/layer_6/attention/output/LayerNorm/beta
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'beta']
INFO - Skipping bert/encoder/layer_6/attention/output/LayerNorm/gamma
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'gamma']
INFO - Skipping bert/encoder/layer_6/attention/output/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_6/attention/output/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'kernel']
INFO - Skipping bert/encoder/layer_6/attention/self/key/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'bias']
INFO - Skipping bert/encoder/layer_6/attention/self/key/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'kernel']
INFO - Skipping bert/encoder/layer_6/attention/self/query/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'bias']
INFO - Skipping bert/encoder/layer_6/attention/self/query/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'kernel']
INFO - Skipping bert/encoder/layer_6/attention/self/value/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'bias']
INFO - Skipping bert/encoder/layer_6/attention/self/value/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'kernel']
INFO - Skipping bert/encoder/layer_6/intermediate/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_6/intermediate/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'kernel']
INFO - Skipping bert/encoder/layer_6/output/LayerNorm/beta
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'beta']
INFO - Skipping bert/encoder/layer_6/output/LayerNorm/gamma
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'gamma']
INFO - Skipping bert/encoder/layer_6/output/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_6/output/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'kernel']
INFO - Skipping bert/encoder/layer_7/attention/output/LayerNorm/beta
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'beta']
INFO - Skipping bert/encoder/layer_7/attention/output/LayerNorm/gamma
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'gamma']
INFO - Skipping bert/encoder/layer_7/attention/output/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_7/attention/output/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'kernel']
INFO - Skipping bert/encoder/layer_7/attention/self/key/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'bias']
INFO - Skipping bert/encoder/layer_7/attention/self/key/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'kernel']
INFO - Skipping bert/encoder/layer_7/attention/self/query/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'bias']
INFO - Skipping bert/encoder/layer_7/attention/self/query/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'kernel']
INFO - Skipping bert/encoder/layer_7/attention/self/value/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'bias']
INFO - Skipping bert/encoder/layer_7/attention/self/value/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'kernel']
INFO - Skipping bert/encoder/layer_7/intermediate/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_7/intermediate/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'kernel']
INFO - Skipping bert/encoder/layer_7/output/LayerNorm/beta
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'beta']
INFO - Skipping bert/encoder/layer_7/output/LayerNorm/gamma
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'gamma']
INFO - Skipping bert/encoder/layer_7/output/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_7/output/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'kernel']
INFO - Skipping bert/encoder/layer_8/attention/output/LayerNorm/beta
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'beta']
INFO - Skipping bert/encoder/layer_8/attention/output/LayerNorm/gamma
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'gamma']
INFO - Skipping bert/encoder/layer_8/attention/output/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_8/attention/output/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'kernel']
INFO - Skipping bert/encoder/layer_8/attention/self/key/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'bias']
INFO - Skipping bert/encoder/layer_8/attention/self/key/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'kernel']
INFO - Skipping bert/encoder/layer_8/attention/self/query/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'bias']
INFO - Skipping bert/encoder/layer_8/attention/self/query/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'kernel']
INFO - Skipping bert/encoder/layer_8/attention/self/value/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'bias']
INFO - Skipping bert/encoder/layer_8/attention/self/value/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'kernel']
INFO - Skipping bert/encoder/layer_8/intermediate/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_8/intermediate/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'kernel']
INFO - Skipping bert/encoder/layer_8/output/LayerNorm/beta
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'beta']
INFO - Skipping bert/encoder/layer_8/output/LayerNorm/gamma
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'gamma']
INFO - Skipping bert/encoder/layer_8/output/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_8/output/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'kernel']
INFO - Skipping bert/encoder/layer_9/attention/output/LayerNorm/beta
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'beta']
INFO - Skipping bert/encoder/layer_9/attention/output/LayerNorm/gamma
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'gamma']
INFO - Skipping bert/encoder/layer_9/attention/output/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_9/attention/output/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'kernel']
INFO - Skipping bert/encoder/layer_9/attention/self/key/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'bias']
INFO - Skipping bert/encoder/layer_9/attention/self/key/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'kernel']
INFO - Skipping bert/encoder/layer_9/attention/self/query/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'bias']
INFO - Skipping bert/encoder/layer_9/attention/self/query/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'kernel']
INFO - Skipping bert/encoder/layer_9/attention/self/value/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'bias']
INFO - Skipping bert/encoder/layer_9/attention/self/value/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'kernel']
INFO - Skipping bert/encoder/layer_9/intermediate/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_9/intermediate/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'kernel']
INFO - Skipping bert/encoder/layer_9/output/LayerNorm/beta
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'beta']
INFO - Skipping bert/encoder/layer_9/output/LayerNorm/gamma
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'gamma']
INFO - Skipping bert/encoder/layer_9/output/dense/bias
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'bias']
INFO - Skipping bert/encoder/layer_9/output/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'kernel']
INFO - Skipping bert/pooler/dense/bias
INFO - Initialize PyTorch weight ['bert', 'pooler', 'dense', 'bias']
INFO - Skipping bert/pooler/dense/kernel
INFO - Initialize PyTorch weight ['bert', 'pooler', 'dense', 'kernel']
DEBUG - Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG - https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-cased-config.json HTTP/1.1" 200 0
INFO - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /root/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.3d5adf10d3445c36ce131f4c6416aa62e9b58e1af56b97664773f4858a46286e
INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": true,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

DEBUG - Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG - https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-cased-pytorch_model.bin HTTP/1.1" 200 0
INFO - loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /root/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
