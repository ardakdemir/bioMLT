I0218 05:16:38.472542 47899242701888 file_utils.py:38] PyTorch version 1.2.0 available.
2020-02-18 05:16:43.247384: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2020-02-18 05:16:43.247818: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2020-02-18 05:16:43.247880: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
I0218 05:17:03.814296 47899242701888 file_utils.py:54] TensorFlow version 2.1.0 available.
I0218 05:17:13.627085 47899242701888 configuration_utils.py:254] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/aakdemir/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.3d5adf10d3445c36ce131f4c6416aa62e9b58e1af56b97664773f4858a46286e
I0218 05:17:13.628237 47899242701888 configuration_utils.py:290] Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": true,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

I0218 05:17:14.389746 47899242701888 modeling_utils.py:458] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/aakdemir/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
I0218 05:17:19.058993 47899242701888 modeling_utils.py:543] Weights of BertForPreTraining not initialized from pretrained model: ['cls.predictions.decoder.bias']
I0218 05:17:19.820200 47899242701888 tokenization_utils.py:418] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/aakdemir/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
I0218 05:17:19.913991 47899242701888 biomlt.py:513] Model loaded  from: save_dir/bert_init_qasfactoid_model_1802
I0218 05:17:35.547875 47899242701888 biomlt.py:513] Model loaded  from: save_dir/bert_init_qasfactoid_model_1802
I0218 05:17:36.027575 47899242701888 reader.py:439] Loading features from cached file squad_cache/./cached_BioASQ-test-factoid-6b-1-snippet_dev_bert-base-cased_384_0.txt
I0218 05:17:36.263706 47899242701888 biomlt.py:665] Evaluation 0 started
I0218 05:17:36.264003 47899242701888 biomlt.py:666] ***** Running evaluation 2_18_5_17_0 with only_preds = True*****
I0218 05:17:36.264127 47899242701888 biomlt.py:667]   Num examples = 164
I0218 05:17:36.266435 47899242701888 biomlt.py:668]   Batch size = 12
Evaluating:   0%|          | 0/14 [00:00<?, ?it/s]Evaluating:   7%|7         | 1/14 [00:00<00:03,  3.99it/s]Evaluating:  14%|#4        | 2/14 [00:00<00:02,  4.73it/s]Evaluating:  21%|##1       | 3/14 [00:00<00:02,  5.46it/s]Evaluating:  29%|##8       | 4/14 [00:00<00:01,  6.14it/s]Evaluating:  36%|###5      | 5/14 [00:00<00:01,  6.71it/s]Evaluating:  43%|####2     | 6/14 [00:00<00:01,  7.19it/s]Evaluating:  50%|#####     | 7/14 [00:00<00:00,  7.58it/s]Evaluating:  57%|#####7    | 8/14 [00:01<00:00,  7.89it/s]Evaluating:  64%|######4   | 9/14 [00:01<00:00,  8.09it/s]Evaluating:  71%|#######1  | 10/14 [00:01<00:00,  8.23it/s]Evaluating:  79%|#######8  | 11/14 [00:01<00:00,  8.34it/s]Evaluating:  86%|########5 | 12/14 [00:01<00:00,  8.43it/s]Evaluating:  93%|#########2| 13/14 [00:01<00:00,  8.50it/s]Evaluating: 100%|##########| 14/14 [00:01<00:00,  8.12it/s]
I0218 05:17:37.991626 47899242701888 squad_metrics.py:392] Writing predictions to: save_dir/predictions_2_18_5_17_0.json
I0218 05:17:37.991749 47899242701888 squad_metrics.py:393] Writing nbest to: biomlt_train_pred_nbest_pred
Picked up JAVA_TOOL_OPTIONS: -XX:+UseSerialGC -Xmx64m -Xms32m
I0218 05:17:45.243570 47888576083008 file_utils.py:38] PyTorch version 1.2.0 available.
2020-02-18 05:17:47.062897: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2020-02-18 05:17:47.063095: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2020-02-18 05:17:47.063116: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
I0218 05:17:48.194394 47888576083008 file_utils.py:54] TensorFlow version 2.1.0 available.
I0218 05:17:49.842725 47888576083008 configuration_utils.py:254] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/aakdemir/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.3d5adf10d3445c36ce131f4c6416aa62e9b58e1af56b97664773f4858a46286e
I0218 05:17:49.843895 47888576083008 configuration_utils.py:290] Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": true,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

I0218 05:17:50.574376 47888576083008 modeling_utils.py:458] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/aakdemir/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
I0218 05:17:53.677044 47888576083008 modeling_utils.py:543] Weights of BertForPreTraining not initialized from pretrained model: ['cls.predictions.decoder.bias']
I0218 05:17:54.393388 47888576083008 tokenization_utils.py:418] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/aakdemir/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
I0218 05:17:54.467652 47888576083008 biomlt.py:513] Model loaded  from: save_dir/bert_init_qasfactoid_model_1802
I0218 05:18:02.803571 47888576083008 biomlt.py:513] Model loaded  from: save_dir/bert_init_qasfactoid_model_1802
I0218 05:18:03.299571 47888576083008 reader.py:439] Loading features from cached file squad_cache/./cached_BioASQ-test-factoid-6b-2-snippet_dev_bert-base-cased_384_0.txt
I0218 05:18:03.335365 47888576083008 biomlt.py:665] Evaluation 0 started
I0218 05:18:03.335515 47888576083008 biomlt.py:666] ***** Running evaluation 2_18_5_17_0 with only_preds = True*****
I0218 05:18:03.335562 47888576083008 biomlt.py:667]   Num examples = 119
I0218 05:18:03.336763 47888576083008 biomlt.py:668]   Batch size = 12
Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]Evaluating:  10%|#         | 1/10 [00:00<00:01,  6.14it/s]Evaluating:  20%|##        | 2/10 [00:00<00:01,  6.61it/s]Evaluating:  30%|###       | 3/10 [00:00<00:00,  7.05it/s]Evaluating:  40%|####      | 4/10 [00:00<00:00,  7.47it/s]Evaluating:  50%|#####     | 5/10 [00:00<00:00,  7.78it/s]Evaluating:  60%|######    | 6/10 [00:00<00:00,  8.03it/s]Evaluating:  70%|#######   | 7/10 [00:00<00:00,  8.20it/s]Evaluating:  80%|########  | 8/10 [00:00<00:00,  8.32it/s]Evaluating:  90%|######### | 9/10 [00:01<00:00,  8.41it/s]Evaluating: 100%|##########| 10/10 [00:01<00:00,  8.73it/s]Evaluating: 100%|##########| 10/10 [00:01<00:00,  8.29it/s]
I0218 05:18:04.544433 47888576083008 squad_metrics.py:392] Writing predictions to: save_dir/predictions_2_18_5_17_0.json
I0218 05:18:04.544548 47888576083008 squad_metrics.py:393] Writing nbest to: biomlt_train_pred_nbest_pred
Picked up JAVA_TOOL_OPTIONS: -XX:+UseSerialGC -Xmx64m -Xms32m
I0218 05:18:10.068655 47010966197312 file_utils.py:38] PyTorch version 1.2.0 available.
2020-02-18 05:18:11.892470: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2020-02-18 05:18:11.892671: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2020-02-18 05:18:11.892693: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
I0218 05:18:13.126764 47010966197312 file_utils.py:54] TensorFlow version 2.1.0 available.
I0218 05:18:14.822571 47010966197312 configuration_utils.py:254] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/aakdemir/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.3d5adf10d3445c36ce131f4c6416aa62e9b58e1af56b97664773f4858a46286e
I0218 05:18:14.823700 47010966197312 configuration_utils.py:290] Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": true,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

I0218 05:18:15.554190 47010966197312 modeling_utils.py:458] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/aakdemir/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
I0218 05:18:18.465076 47010966197312 modeling_utils.py:543] Weights of BertForPreTraining not initialized from pretrained model: ['cls.predictions.decoder.bias']
I0218 05:18:19.224043 47010966197312 tokenization_utils.py:418] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/aakdemir/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
I0218 05:18:19.297246 47010966197312 biomlt.py:513] Model loaded  from: save_dir/bert_init_qasfactoid_model_1802
I0218 05:18:27.918547 47010966197312 biomlt.py:513] Model loaded  from: save_dir/bert_init_qasfactoid_model_1802
I0218 05:18:28.374988 47010966197312 reader.py:439] Loading features from cached file squad_cache/./cached_BioASQ-test-factoid-6b-3-snippet_dev_bert-base-cased_384_0.txt
I0218 05:18:28.420989 47010966197312 biomlt.py:665] Evaluation 0 started
I0218 05:18:28.421188 47010966197312 biomlt.py:666] ***** Running evaluation 2_18_5_18_0 with only_preds = True*****
I0218 05:18:28.421262 47010966197312 biomlt.py:667]   Num examples = 130
I0218 05:18:28.423573 47010966197312 biomlt.py:668]   Batch size = 12
Evaluating:   0%|          | 0/11 [00:00<?, ?it/s]Evaluating:   9%|9         | 1/11 [00:00<00:01,  6.25it/s]Evaluating:  18%|#8        | 2/11 [00:00<00:01,  6.80it/s]Evaluating:  27%|##7       | 3/11 [00:00<00:01,  7.27it/s]Evaluating:  36%|###6      | 4/11 [00:00<00:00,  7.63it/s]Evaluating:  45%|####5     | 5/11 [00:00<00:00,  7.91it/s]Evaluating:  55%|#####4    | 6/11 [00:00<00:00,  8.12it/s]Evaluating:  64%|######3   | 7/11 [00:00<00:00,  8.24it/s]Evaluating:  73%|#######2  | 8/11 [00:00<00:00,  8.36it/s]Evaluating:  82%|########1 | 9/11 [00:01<00:00,  8.45it/s]Evaluating:  91%|######### | 10/11 [00:01<00:00,  8.51it/s]Evaluating: 100%|##########| 11/11 [00:01<00:00,  8.46it/s]
I0218 05:18:29.726239 47010966197312 squad_metrics.py:392] Writing predictions to: save_dir/predictions_2_18_5_18_0.json
I0218 05:18:29.726380 47010966197312 squad_metrics.py:393] Writing nbest to: biomlt_train_pred_nbest_pred
Picked up JAVA_TOOL_OPTIONS: -XX:+UseSerialGC -Xmx64m -Xms32m
I0218 05:18:35.607474 47760801059904 file_utils.py:38] PyTorch version 1.2.0 available.
2020-02-18 05:18:37.433491: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2020-02-18 05:18:37.433686: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2020-02-18 05:18:37.433707: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
I0218 05:18:38.668439 47760801059904 file_utils.py:54] TensorFlow version 2.1.0 available.
I0218 05:18:40.399752 47760801059904 configuration_utils.py:254] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/aakdemir/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.3d5adf10d3445c36ce131f4c6416aa62e9b58e1af56b97664773f4858a46286e
I0218 05:18:40.400924 47760801059904 configuration_utils.py:290] Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": true,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

I0218 05:18:41.129333 47760801059904 modeling_utils.py:458] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/aakdemir/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
I0218 05:18:44.079130 47760801059904 modeling_utils.py:543] Weights of BertForPreTraining not initialized from pretrained model: ['cls.predictions.decoder.bias']
I0218 05:18:44.817312 47760801059904 tokenization_utils.py:418] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/aakdemir/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
I0218 05:18:44.890801 47760801059904 biomlt.py:513] Model loaded  from: save_dir/bert_init_qasfactoid_model_1802
I0218 05:18:53.400577 47760801059904 biomlt.py:513] Model loaded  from: save_dir/bert_init_qasfactoid_model_1802
I0218 05:18:54.007794 47760801059904 reader.py:439] Loading features from cached file squad_cache/./cached_BioASQ-test-factoid-6b-4-snippet_dev_bert-base-cased_384_0.txt
I0218 05:18:54.165226 47760801059904 biomlt.py:665] Evaluation 0 started
I0218 05:18:54.165524 47760801059904 biomlt.py:666] ***** Running evaluation 2_18_5_18_0 with only_preds = True*****
I0218 05:18:54.165656 47760801059904 biomlt.py:667]   Num examples = 114
I0218 05:18:54.168565 47760801059904 biomlt.py:668]   Batch size = 12
Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]Evaluating:  10%|#         | 1/10 [00:00<00:01,  4.86it/s]Evaluating:  20%|##        | 2/10 [00:00<00:01,  5.52it/s]Evaluating:  30%|###       | 3/10 [00:00<00:01,  6.16it/s]Evaluating:  40%|####      | 4/10 [00:00<00:00,  6.74it/s]Evaluating:  50%|#####     | 5/10 [00:00<00:00,  7.21it/s]Evaluating:  60%|######    | 6/10 [00:00<00:00,  7.58it/s]Evaluating:  70%|#######   | 7/10 [00:00<00:00,  7.88it/s]Evaluating:  80%|########  | 8/10 [00:01<00:00,  8.11it/s]Evaluating:  90%|######### | 9/10 [00:01<00:00,  8.25it/s]Evaluating: 100%|##########| 10/10 [00:01<00:00,  8.31it/s]
I0218 05:18:55.375498 47760801059904 squad_metrics.py:392] Writing predictions to: save_dir/predictions_2_18_5_18_0.json
I0218 05:18:55.375707 47760801059904 squad_metrics.py:393] Writing nbest to: biomlt_train_pred_nbest_pred
Picked up JAVA_TOOL_OPTIONS: -XX:+UseSerialGC -Xmx64m -Xms32m
I0218 05:19:01.355403 47765563102272 file_utils.py:38] PyTorch version 1.2.0 available.
2020-02-18 05:19:03.184576: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2020-02-18 05:19:03.184771: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2020-02-18 05:19:03.184793: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
I0218 05:19:04.587336 47765563102272 file_utils.py:54] TensorFlow version 2.1.0 available.
I0218 05:19:06.184440 47765563102272 configuration_utils.py:254] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/aakdemir/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.3d5adf10d3445c36ce131f4c6416aa62e9b58e1af56b97664773f4858a46286e
I0218 05:19:06.185567 47765563102272 configuration_utils.py:290] Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": true,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

I0218 05:19:06.951498 47765563102272 modeling_utils.py:458] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/aakdemir/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
I0218 05:19:10.031758 47765563102272 modeling_utils.py:543] Weights of BertForPreTraining not initialized from pretrained model: ['cls.predictions.decoder.bias']
I0218 05:19:10.900274 47765563102272 tokenization_utils.py:418] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/aakdemir/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
I0218 05:19:10.975806 47765563102272 biomlt.py:513] Model loaded  from: save_dir/bert_init_qasfactoid_model_1802
I0218 05:19:19.590065 47765563102272 biomlt.py:513] Model loaded  from: save_dir/bert_init_qasfactoid_model_1802
I0218 05:19:20.128062 47765563102272 reader.py:439] Loading features from cached file squad_cache/./cached_BioASQ-test-factoid-6b-5-snippet_dev_bert-base-cased_384_0.txt
I0218 05:19:20.170592 47765563102272 biomlt.py:665] Evaluation 0 started
I0218 05:19:20.170743 47765563102272 biomlt.py:666] ***** Running evaluation 2_18_5_19_0 with only_preds = True*****
I0218 05:19:20.170800 47765563102272 biomlt.py:667]   Num examples = 183
I0218 05:19:20.171864 47765563102272 biomlt.py:668]   Batch size = 12
Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]Evaluating:   6%|6         | 1/16 [00:00<00:02,  6.66it/s]Evaluating:  12%|#2        | 2/16 [00:00<00:01,  7.13it/s]Evaluating:  19%|#8        | 3/16 [00:00<00:01,  7.50it/s]Evaluating:  25%|##5       | 4/16 [00:00<00:01,  7.79it/s]Evaluating:  31%|###1      | 5/16 [00:00<00:01,  8.01it/s]Evaluating:  38%|###7      | 6/16 [00:00<00:01,  8.17it/s]Evaluating:  44%|####3     | 7/16 [00:00<00:01,  8.26it/s]Evaluating:  50%|#####     | 8/16 [00:00<00:00,  8.33it/s]Evaluating:  56%|#####6    | 9/16 [00:01<00:00,  8.39it/s]Evaluating:  62%|######2   | 10/16 [00:01<00:00,  8.46it/s]Evaluating:  69%|######8   | 11/16 [00:01<00:00,  8.51it/s]Evaluating:  75%|#######5  | 12/16 [00:01<00:00,  8.54it/s]Evaluating:  81%|########1 | 13/16 [00:01<00:00,  8.56it/s]Evaluating:  88%|########7 | 14/16 [00:01<00:00,  8.56it/s]Evaluating:  94%|#########3| 15/16 [00:01<00:00,  8.58it/s]Evaluating: 100%|##########| 16/16 [00:01<00:00,  8.81it/s]
I0218 05:19:21.989319 47765563102272 squad_metrics.py:392] Writing predictions to: save_dir/predictions_2_18_5_19_0.json
I0218 05:19:21.989484 47765563102272 squad_metrics.py:393] Writing nbest to: biomlt_train_pred_nbest_pred
Picked up JAVA_TOOL_OPTIONS: -XX:+UseSerialGC -Xmx64m -Xms32m
I0218 05:24:41.215125 47538515665984 file_utils.py:38] PyTorch version 1.2.0 available.
2020-02-18 05:24:45.501202: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2020-02-18 05:24:45.501699: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2020-02-18 05:24:45.501762: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
I0218 05:24:55.279562 47538515665984 file_utils.py:54] TensorFlow version 2.1.0 available.
I0218 05:24:58.535679 47538515665984 configuration_utils.py:252] loading configuration file ../biobert_data/biobert_v1.1_pubmed/config.json
I0218 05:24:58.536311 47538515665984 configuration_utils.py:290] Model config BertConfig {
  "architectures": null,
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": true,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

I0218 05:24:58.537618 47538515665984 modeling_utils.py:456] loading weights file ../biobert_data/biobert_v1.1_pubmed/model.ckpt.index
I0218 05:25:01.022135 47538515665984 modeling_bert.py:74] Converting TensorFlow checkpoint from /home/aakdemir/biobert_data/biobert_v1.1_pubmed/model.ckpt
I0218 05:25:01.059723 47538515665984 modeling_bert.py:80] Loading TF weight bert/embeddings/LayerNorm/beta with shape [768]
I0218 05:25:01.190904 47538515665984 modeling_bert.py:80] Loading TF weight bert/embeddings/LayerNorm/gamma with shape [768]
I0218 05:25:01.241245 47538515665984 modeling_bert.py:80] Loading TF weight bert/embeddings/position_embeddings with shape [512, 768]
I0218 05:25:01.260447 47538515665984 modeling_bert.py:80] Loading TF weight bert/embeddings/token_type_embeddings with shape [2, 768]
I0218 05:25:01.285384 47538515665984 modeling_bert.py:80] Loading TF weight bert/embeddings/word_embeddings with shape [28996, 768]
I0218 05:25:01.798293 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/beta with shape [768]
I0218 05:25:01.828795 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/gamma with shape [768]
I0218 05:25:01.832841 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/output/dense/bias with shape [768]
I0218 05:25:01.836698 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/output/dense/kernel with shape [768, 768]
I0218 05:25:01.875926 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/self/key/bias with shape [768]
I0218 05:25:01.890401 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/self/key/kernel with shape [768, 768]
I0218 05:25:01.940659 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/self/query/bias with shape [768]
I0218 05:25:01.961707 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/self/query/kernel with shape [768, 768]
I0218 05:25:01.995329 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/self/value/bias with shape [768]
I0218 05:25:02.008902 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/self/value/kernel with shape [768, 768]
I0218 05:25:02.033518 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/intermediate/dense/bias with shape [3072]
I0218 05:25:02.066129 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/intermediate/dense/kernel with shape [768, 3072]
I0218 05:25:02.137007 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/output/LayerNorm/beta with shape [768]
I0218 05:25:02.148776 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/output/LayerNorm/gamma with shape [768]
I0218 05:25:02.152204 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/output/dense/bias with shape [768]
I0218 05:25:02.154987 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/output/dense/kernel with shape [3072, 768]
I0218 05:25:02.222230 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/beta with shape [768]
I0218 05:25:02.236682 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/gamma with shape [768]
I0218 05:25:02.240039 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/output/dense/bias with shape [768]
I0218 05:25:02.243188 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/output/dense/kernel with shape [768, 768]
I0218 05:25:02.266832 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/self/key/bias with shape [768]
I0218 05:25:02.279580 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/self/key/kernel with shape [768, 768]
I0218 05:25:02.292809 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/self/query/bias with shape [768]
I0218 05:25:02.305932 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/self/query/kernel with shape [768, 768]
I0218 05:25:02.345208 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/self/value/bias with shape [768]
I0218 05:25:02.369554 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/self/value/kernel with shape [768, 768]
I0218 05:25:02.392502 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/intermediate/dense/bias with shape [3072]
I0218 05:25:02.404045 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/intermediate/dense/kernel with shape [768, 3072]
I0218 05:25:02.469334 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/output/LayerNorm/beta with shape [768]
I0218 05:25:02.476959 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/output/LayerNorm/gamma with shape [768]
I0218 05:25:02.479619 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/output/dense/bias with shape [768]
I0218 05:25:02.482576 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/output/dense/kernel with shape [3072, 768]
I0218 05:25:02.536957 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/beta with shape [768]
I0218 05:25:02.550509 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/gamma with shape [768]
I0218 05:25:02.553931 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/output/dense/bias with shape [768]
I0218 05:25:02.556732 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/output/dense/kernel with shape [768, 768]
I0218 05:25:02.573072 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/self/key/bias with shape [768]
I0218 05:25:02.581014 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/self/key/kernel with shape [768, 768]
I0218 05:25:02.610125 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/self/query/bias with shape [768]
I0218 05:25:02.635514 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/self/query/kernel with shape [768, 768]
I0218 05:25:02.662045 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/self/value/bias with shape [768]
I0218 05:25:02.672978 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/self/value/kernel with shape [768, 768]
I0218 05:25:02.691066 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/intermediate/dense/bias with shape [3072]
I0218 05:25:02.704967 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/intermediate/dense/kernel with shape [768, 3072]
I0218 05:25:02.784432 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/output/LayerNorm/beta with shape [768]
I0218 05:25:02.795809 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/output/LayerNorm/gamma with shape [768]
I0218 05:25:02.799472 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/output/dense/bias with shape [768]
I0218 05:25:02.802830 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/output/dense/kernel with shape [3072, 768]
I0218 05:25:02.863540 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/beta with shape [768]
I0218 05:25:02.892331 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/gamma with shape [768]
I0218 05:25:02.895211 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/output/dense/bias with shape [768]
I0218 05:25:02.899012 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/output/dense/kernel with shape [768, 768]
I0218 05:25:02.936523 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/self/key/bias with shape [768]
I0218 05:25:02.961304 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/self/key/kernel with shape [768, 768]
I0218 05:25:02.979103 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/self/query/bias with shape [768]
I0218 05:25:02.986557 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/self/query/kernel with shape [768, 768]
I0218 05:25:03.005155 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/self/value/bias with shape [768]
I0218 05:25:03.012953 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/self/value/kernel with shape [768, 768]
I0218 05:25:03.036215 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/intermediate/dense/bias with shape [3072]
I0218 05:25:03.047946 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/intermediate/dense/kernel with shape [768, 3072]
I0218 05:25:03.095530 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/output/LayerNorm/beta with shape [768]
I0218 05:25:03.107354 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/output/LayerNorm/gamma with shape [768]
I0218 05:25:03.112481 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/output/dense/bias with shape [768]
I0218 05:25:03.120796 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/output/dense/kernel with shape [3072, 768]
I0218 05:25:03.205411 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/beta with shape [768]
I0218 05:25:03.217459 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/gamma with shape [768]
I0218 05:25:03.223388 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/output/dense/bias with shape [768]
I0218 05:25:03.231759 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/output/dense/kernel with shape [768, 768]
I0218 05:25:03.252373 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/self/key/bias with shape [768]
I0218 05:25:03.266088 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/self/key/kernel with shape [768, 768]
I0218 05:25:03.286054 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/self/query/bias with shape [768]
I0218 05:25:03.302922 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/self/query/kernel with shape [768, 768]
I0218 05:25:03.325825 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/self/value/bias with shape [768]
I0218 05:25:03.337645 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/self/value/kernel with shape [768, 768]
I0218 05:25:03.358484 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/intermediate/dense/bias with shape [3072]
I0218 05:25:03.370861 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/intermediate/dense/kernel with shape [768, 3072]
I0218 05:25:03.425440 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/output/LayerNorm/beta with shape [768]
I0218 05:25:03.437539 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/output/LayerNorm/gamma with shape [768]
I0218 05:25:03.440344 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/output/dense/bias with shape [768]
I0218 05:25:03.442488 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/output/dense/kernel with shape [3072, 768]
I0218 05:25:03.498454 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/beta with shape [768]
I0218 05:25:03.518667 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/gamma with shape [768]
I0218 05:25:03.522132 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/output/dense/bias with shape [768]
I0218 05:25:03.525339 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/output/dense/kernel with shape [768, 768]
I0218 05:25:03.565218 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/self/key/bias with shape [768]
I0218 05:25:03.607010 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/self/key/kernel with shape [768, 768]
I0218 05:25:03.635959 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/self/query/bias with shape [768]
I0218 05:25:03.646726 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/self/query/kernel with shape [768, 768]
I0218 05:25:03.664774 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/self/value/bias with shape [768]
I0218 05:25:03.678693 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/self/value/kernel with shape [768, 768]
I0218 05:25:03.699478 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/intermediate/dense/bias with shape [3072]
I0218 05:25:03.713531 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/intermediate/dense/kernel with shape [768, 3072]
I0218 05:25:03.782732 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/output/LayerNorm/beta with shape [768]
I0218 05:25:03.824638 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/output/LayerNorm/gamma with shape [768]
I0218 05:25:03.827585 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/output/dense/bias with shape [768]
I0218 05:25:03.830895 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/output/dense/kernel with shape [3072, 768]
I0218 05:25:03.906393 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/beta with shape [768]
I0218 05:25:03.926411 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/gamma with shape [768]
I0218 05:25:03.931298 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/output/dense/bias with shape [768]
I0218 05:25:03.934071 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/output/dense/kernel with shape [768, 768]
I0218 05:25:03.954540 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/self/key/bias with shape [768]
I0218 05:25:03.987376 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/self/key/kernel with shape [768, 768]
I0218 05:25:04.022510 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/self/query/bias with shape [768]
I0218 05:25:04.038086 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/self/query/kernel with shape [768, 768]
I0218 05:25:04.057872 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/self/value/bias with shape [768]
I0218 05:25:04.091910 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/self/value/kernel with shape [768, 768]
I0218 05:25:04.124588 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/intermediate/dense/bias with shape [3072]
I0218 05:25:04.140623 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/intermediate/dense/kernel with shape [768, 3072]
I0218 05:25:04.203397 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/output/LayerNorm/beta with shape [768]
I0218 05:25:04.218147 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/output/LayerNorm/gamma with shape [768]
I0218 05:25:04.221437 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/output/dense/bias with shape [768]
I0218 05:25:04.224550 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/output/dense/kernel with shape [3072, 768]
I0218 05:25:04.290118 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/beta with shape [768]
I0218 05:25:04.305627 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/gamma with shape [768]
I0218 05:25:04.308779 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/output/dense/bias with shape [768]
I0218 05:25:04.312259 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/output/dense/kernel with shape [768, 768]
I0218 05:25:04.336092 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/self/key/bias with shape [768]
I0218 05:25:04.346320 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/self/key/kernel with shape [768, 768]
I0218 05:25:04.364865 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/self/query/bias with shape [768]
I0218 05:25:04.405792 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/self/query/kernel with shape [768, 768]
I0218 05:25:04.426092 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/self/value/bias with shape [768]
I0218 05:25:04.440320 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/self/value/kernel with shape [768, 768]
I0218 05:25:04.459109 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/intermediate/dense/bias with shape [3072]
I0218 05:25:04.471812 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/intermediate/dense/kernel with shape [768, 3072]
I0218 05:25:04.532964 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/output/LayerNorm/beta with shape [768]
I0218 05:25:04.548028 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/output/LayerNorm/gamma with shape [768]
I0218 05:25:04.551238 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/output/dense/bias with shape [768]
I0218 05:25:04.554200 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/output/dense/kernel with shape [3072, 768]
I0218 05:25:04.598927 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/beta with shape [768]
I0218 05:25:04.612240 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/gamma with shape [768]
I0218 05:25:04.615142 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/output/dense/bias with shape [768]
I0218 05:25:04.617866 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/output/dense/kernel with shape [768, 768]
I0218 05:25:04.644933 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/self/key/bias with shape [768]
I0218 05:25:04.657961 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/self/key/kernel with shape [768, 768]
I0218 05:25:04.676032 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/self/query/bias with shape [768]
I0218 05:25:04.689372 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/self/query/kernel with shape [768, 768]
I0218 05:25:04.710717 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/self/value/bias with shape [768]
I0218 05:25:04.724085 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/self/value/kernel with shape [768, 768]
I0218 05:25:04.746644 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/intermediate/dense/bias with shape [3072]
I0218 05:25:04.759395 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/intermediate/dense/kernel with shape [768, 3072]
I0218 05:25:04.861898 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/output/LayerNorm/beta with shape [768]
I0218 05:25:04.888646 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/output/LayerNorm/gamma with shape [768]
I0218 05:25:04.892334 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/output/dense/bias with shape [768]
I0218 05:25:04.895209 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/output/dense/kernel with shape [3072, 768]
I0218 05:25:04.952046 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/beta with shape [768]
I0218 05:25:04.965915 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/gamma with shape [768]
I0218 05:25:04.972369 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/output/dense/bias with shape [768]
I0218 05:25:04.980706 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/output/dense/kernel with shape [768, 768]
I0218 05:25:05.000310 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/self/key/bias with shape [768]
I0218 05:25:05.013536 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/self/key/kernel with shape [768, 768]
I0218 05:25:05.053136 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/self/query/bias with shape [768]
I0218 05:25:05.081683 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/self/query/kernel with shape [768, 768]
I0218 05:25:05.103592 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/self/value/bias with shape [768]
I0218 05:25:05.134442 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/self/value/kernel with shape [768, 768]
I0218 05:25:05.167724 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/intermediate/dense/bias with shape [3072]
I0218 05:25:05.183564 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/intermediate/dense/kernel with shape [768, 3072]
I0218 05:25:05.270147 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/output/LayerNorm/beta with shape [768]
I0218 05:25:05.282630 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/output/LayerNorm/gamma with shape [768]
I0218 05:25:05.285747 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/output/dense/bias with shape [768]
I0218 05:25:05.294921 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/output/dense/kernel with shape [3072, 768]
I0218 05:25:05.367434 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/beta with shape [768]
I0218 05:25:05.381518 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/gamma with shape [768]
I0218 05:25:05.388190 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/output/dense/bias with shape [768]
I0218 05:25:05.390715 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/output/dense/kernel with shape [768, 768]
I0218 05:25:05.407507 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/self/key/bias with shape [768]
I0218 05:25:05.419674 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/self/key/kernel with shape [768, 768]
I0218 05:25:05.442795 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/self/query/bias with shape [768]
I0218 05:25:05.456063 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/self/query/kernel with shape [768, 768]
I0218 05:25:05.475299 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/self/value/bias with shape [768]
I0218 05:25:05.489157 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/self/value/kernel with shape [768, 768]
I0218 05:25:05.506830 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/intermediate/dense/bias with shape [3072]
I0218 05:25:05.520023 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/intermediate/dense/kernel with shape [768, 3072]
I0218 05:25:05.579343 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/output/LayerNorm/beta with shape [768]
I0218 05:25:05.591032 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/output/LayerNorm/gamma with shape [768]
I0218 05:25:05.593710 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/output/dense/bias with shape [768]
I0218 05:25:05.596261 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/output/dense/kernel with shape [3072, 768]
I0218 05:25:05.732431 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/beta with shape [768]
I0218 05:25:05.776300 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/gamma with shape [768]
I0218 05:25:05.779402 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/output/dense/bias with shape [768]
I0218 05:25:05.782776 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/output/dense/kernel with shape [768, 768]
I0218 05:25:05.809608 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/self/key/bias with shape [768]
I0218 05:25:05.824175 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/self/key/kernel with shape [768, 768]
I0218 05:25:05.860554 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/self/query/bias with shape [768]
I0218 05:25:05.893439 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/self/query/kernel with shape [768, 768]
I0218 05:25:05.912752 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/self/value/bias with shape [768]
I0218 05:25:05.927971 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/self/value/kernel with shape [768, 768]
I0218 05:25:05.959061 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/intermediate/dense/bias with shape [3072]
I0218 05:25:05.973676 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/intermediate/dense/kernel with shape [768, 3072]
I0218 05:25:06.074790 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/output/LayerNorm/beta with shape [768]
I0218 05:25:06.094524 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/output/LayerNorm/gamma with shape [768]
I0218 05:25:06.098392 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/output/dense/bias with shape [768]
I0218 05:25:06.102475 47538515665984 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/output/dense/kernel with shape [3072, 768]
I0218 05:25:06.172142 47538515665984 modeling_bert.py:80] Loading TF weight bert/pooler/dense/bias with shape [768]
I0218 05:25:06.190056 47538515665984 modeling_bert.py:80] Loading TF weight bert/pooler/dense/kernel with shape [768, 768]
I0218 05:25:06.214223 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'beta']
I0218 05:25:06.214796 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'gamma']
I0218 05:25:06.215061 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'embeddings', 'position_embeddings']
I0218 05:25:06.215267 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'embeddings', 'token_type_embeddings']
I0218 05:25:06.215452 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'embeddings', 'word_embeddings']
I0218 05:25:06.216645 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:25:06.217028 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:25:06.217313 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'bias']
I0218 05:25:06.217607 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'kernel']
I0218 05:25:06.217855 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'bias']
I0218 05:25:06.218110 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'kernel']
I0218 05:25:06.218348 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'bias']
I0218 05:25:06.218577 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'kernel']
I0218 05:25:06.218801 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'bias']
I0218 05:25:06.219038 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'kernel']
I0218 05:25:06.219270 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'bias']
I0218 05:25:06.219491 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'kernel']
I0218 05:25:06.219994 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'beta']
I0218 05:25:06.220258 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'gamma']
I0218 05:25:06.220478 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'bias']
I0218 05:25:06.220697 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'kernel']
I0218 05:25:06.221534 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:25:06.221782 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:25:06.222023 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'bias']
I0218 05:25:06.222236 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'kernel']
I0218 05:25:06.222450 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'bias']
I0218 05:25:06.222658 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'kernel']
I0218 05:25:06.222861 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'bias']
I0218 05:25:06.223083 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'kernel']
I0218 05:25:06.223284 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'bias']
I0218 05:25:06.223486 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'kernel']
I0218 05:25:06.223697 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'bias']
I0218 05:25:06.223942 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'kernel']
I0218 05:25:06.224383 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'beta']
I0218 05:25:06.224606 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'gamma']
I0218 05:25:06.224805 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'bias']
I0218 05:25:06.225016 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'kernel']
I0218 05:25:06.225759 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:25:06.226020 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:25:06.226236 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'bias']
I0218 05:25:06.226450 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'kernel']
I0218 05:25:06.226660 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'bias']
I0218 05:25:06.226865 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'kernel']
I0218 05:25:06.227088 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'bias']
I0218 05:25:06.227293 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'kernel']
I0218 05:25:06.227496 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'bias']
I0218 05:25:06.227700 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'kernel']
I0218 05:25:06.227910 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'bias']
I0218 05:25:06.228114 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'kernel']
I0218 05:25:06.228835 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'beta']
I0218 05:25:06.229084 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'gamma']
I0218 05:25:06.229287 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'bias']
I0218 05:25:06.229489 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'kernel']
I0218 05:25:06.229934 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:25:06.230170 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:25:06.230376 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'bias']
I0218 05:25:06.230583 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'kernel']
I0218 05:25:06.230791 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'bias']
I0218 05:25:06.231011 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'kernel']
I0218 05:25:06.231247 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'bias']
I0218 05:25:06.231441 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'kernel']
I0218 05:25:06.231631 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'bias']
I0218 05:25:06.231820 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'kernel']
I0218 05:25:06.232022 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'bias']
I0218 05:25:06.232218 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'kernel']
I0218 05:25:06.232904 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'beta']
I0218 05:25:06.233122 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'gamma']
I0218 05:25:06.233312 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'bias']
I0218 05:25:06.233500 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'kernel']
I0218 05:25:06.233929 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:25:06.234151 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:25:06.234346 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'bias']
I0218 05:25:06.234539 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'kernel']
I0218 05:25:06.234742 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'bias']
I0218 05:25:06.234949 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'kernel']
I0218 05:25:06.235143 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'bias']
I0218 05:25:06.235331 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'kernel']
I0218 05:25:06.235519 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'bias']
I0218 05:25:06.235706 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'kernel']
I0218 05:25:06.235914 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'bias']
I0218 05:25:06.236102 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'kernel']
I0218 05:25:06.236502 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'beta']
I0218 05:25:06.236711 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'gamma']
I0218 05:25:06.236910 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'bias']
I0218 05:25:06.237097 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'kernel']
I0218 05:25:06.237804 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:25:06.238069 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:25:06.238270 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'bias']
I0218 05:25:06.238464 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'kernel']
I0218 05:25:06.238665 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'bias']
I0218 05:25:06.238857 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'kernel']
I0218 05:25:06.239063 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'bias']
I0218 05:25:06.239252 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'kernel']
I0218 05:25:06.239441 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'bias']
I0218 05:25:06.239629 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'kernel']
I0218 05:25:06.239820 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'bias']
I0218 05:25:06.240017 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'kernel']
I0218 05:25:06.240422 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'beta']
I0218 05:25:06.240633 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'gamma']
I0218 05:25:06.240819 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'bias']
I0218 05:25:06.241023 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'kernel']
I0218 05:25:06.241719 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:25:06.241957 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:25:06.242157 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'bias']
I0218 05:25:06.242353 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'kernel']
I0218 05:25:06.242537 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'bias']
I0218 05:25:06.242717 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'kernel']
I0218 05:25:06.242902 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'bias']
I0218 05:25:06.243079 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'kernel']
I0218 05:25:06.243254 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'bias']
I0218 05:25:06.243427 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'kernel']
I0218 05:25:06.243603 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'bias']
I0218 05:25:06.243802 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'kernel']
I0218 05:25:06.244192 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'beta']
I0218 05:25:06.244392 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'gamma']
I0218 05:25:06.244566 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'bias']
I0218 05:25:06.244737 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'kernel']
I0218 05:25:06.245395 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:25:06.245605 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:25:06.245790 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'bias']
I0218 05:25:06.245983 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'kernel']
I0218 05:25:06.246170 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'bias']
I0218 05:25:06.246347 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'kernel']
I0218 05:25:06.246524 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'bias']
I0218 05:25:06.246700 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'kernel']
I0218 05:25:06.246873 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'bias']
I0218 05:25:06.247067 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'kernel']
I0218 05:25:06.247246 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'bias']
I0218 05:25:06.247417 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'kernel']
I0218 05:25:06.247793 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'beta']
I0218 05:25:06.248000 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'gamma']
I0218 05:25:06.248176 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'bias']
I0218 05:25:06.248350 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'kernel']
I0218 05:25:06.249012 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:25:06.249224 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:25:06.249408 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'bias']
I0218 05:25:06.249588 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'kernel']
I0218 05:25:06.249772 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'bias']
I0218 05:25:06.249970 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'kernel']
I0218 05:25:06.250175 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'bias']
I0218 05:25:06.250357 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'kernel']
I0218 05:25:06.250532 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'bias']
I0218 05:25:06.250709 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'kernel']
I0218 05:25:06.250920 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'bias']
I0218 05:25:06.251102 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'kernel']
I0218 05:25:06.251475 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'beta']
I0218 05:25:06.251670 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'gamma']
I0218 05:25:06.251842 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'bias']
I0218 05:25:06.252028 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'kernel']
I0218 05:25:06.252675 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:25:06.252899 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:25:06.253090 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'bias']
I0218 05:25:06.253260 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'kernel']
I0218 05:25:06.253433 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'bias']
I0218 05:25:06.253601 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'kernel']
I0218 05:25:06.253767 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'bias']
I0218 05:25:06.253942 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'kernel']
I0218 05:25:06.254109 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'bias']
I0218 05:25:06.254274 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'kernel']
I0218 05:25:06.254441 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'bias']
I0218 05:25:06.254602 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'kernel']
I0218 05:25:06.254956 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'beta']
I0218 05:25:06.255144 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'gamma']
I0218 05:25:06.255307 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'bias']
I0218 05:25:06.255468 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'kernel']
I0218 05:25:06.255840 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:25:06.256067 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:25:06.256239 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'bias']
I0218 05:25:06.256408 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'kernel']
I0218 05:25:06.256575 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'bias']
I0218 05:25:06.256741 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'kernel']
I0218 05:25:06.256915 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'bias']
I0218 05:25:06.257082 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'kernel']
I0218 05:25:06.257246 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'bias']
I0218 05:25:06.257411 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'kernel']
I0218 05:25:06.257575 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'bias']
I0218 05:25:06.257737 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'kernel']
I0218 05:25:06.258337 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'beta']
I0218 05:25:06.258529 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'gamma']
I0218 05:25:06.258693 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'bias']
I0218 05:25:06.258855 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'kernel']
I0218 05:25:06.259241 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:25:06.259432 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:25:06.259600 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'bias']
I0218 05:25:06.259768 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'kernel']
I0218 05:25:06.259952 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'bias']
I0218 05:25:06.260124 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'kernel']
I0218 05:25:06.260288 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'bias']
I0218 05:25:06.260453 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'kernel']
I0218 05:25:06.260616 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'bias']
I0218 05:25:06.260780 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'kernel']
I0218 05:25:06.260950 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'bias']
I0218 05:25:06.261111 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'kernel']
I0218 05:25:06.261474 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'beta']
I0218 05:25:06.261662 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'gamma']
I0218 05:25:06.261825 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'bias']
I0218 05:25:06.262008 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'kernel']
I0218 05:25:06.262334 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'pooler', 'dense', 'bias']
I0218 05:25:06.262506 47538515665984 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'pooler', 'dense', 'kernel']
I0218 05:25:07.083019 47538515665984 tokenization_utils.py:418] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/aakdemir/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
I0218 05:25:07.165637 47538515665984 biomlt.py:513] Model loaded  from: save_dir/pubmedbiobert_init_qasfactoid6b_1802
I0218 05:25:23.188247 47538515665984 biomlt.py:513] Model loaded  from: save_dir/pubmedbiobert_init_qasfactoid6b_1802
I0218 05:25:23.932685 47538515665984 reader.py:439] Loading features from cached file squad_cache/./cached_BioASQ-test-factoid-6b-1-snippet_dev_bert-base-cased_384_0.txt
I0218 05:25:23.968281 47538515665984 biomlt.py:665] Evaluation 0 started
I0218 05:25:23.968536 47538515665984 biomlt.py:666] ***** Running evaluation 2_18_5_24_0 with only_preds = True*****
I0218 05:25:23.968660 47538515665984 biomlt.py:667]   Num examples = 164
I0218 05:25:23.972219 47538515665984 biomlt.py:668]   Batch size = 12
Evaluating:   0%|          | 0/14 [00:00<?, ?it/s]Evaluating:   7%|7         | 1/14 [00:00<00:03,  3.99it/s]Evaluating:  14%|#4        | 2/14 [00:00<00:02,  4.72it/s]Evaluating:  21%|##1       | 3/14 [00:00<00:02,  5.43it/s]Evaluating:  29%|##8       | 4/14 [00:00<00:01,  6.08it/s]Evaluating:  36%|###5      | 5/14 [00:00<00:01,  6.64it/s]Evaluating:  43%|####2     | 6/14 [00:00<00:01,  7.13it/s]Evaluating:  50%|#####     | 7/14 [00:00<00:00,  7.52it/s]Evaluating:  57%|#####7    | 8/14 [00:01<00:00,  7.80it/s]Evaluating:  64%|######4   | 9/14 [00:01<00:00,  8.00it/s]Evaluating:  71%|#######1  | 10/14 [00:01<00:00,  8.14it/s]Evaluating:  79%|#######8  | 11/14 [00:01<00:00,  8.28it/s]Evaluating:  86%|########5 | 12/14 [00:01<00:00,  8.37it/s]Evaluating:  93%|#########2| 13/14 [00:01<00:00,  8.45it/s]Evaluating: 100%|##########| 14/14 [00:01<00:00,  8.05it/s]
I0218 05:25:25.714607 47538515665984 squad_metrics.py:392] Writing predictions to: save_dir/predictions_2_18_5_24_0.json
I0218 05:25:25.714734 47538515665984 squad_metrics.py:393] Writing nbest to: biomlt_train_pred_nbest_pred
Picked up JAVA_TOOL_OPTIONS: -XX:+UseSerialGC -Xmx64m -Xms32m
I0218 05:25:32.680993 47488301069376 file_utils.py:38] PyTorch version 1.2.0 available.
2020-02-18 05:25:34.801110: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2020-02-18 05:25:34.801343: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2020-02-18 05:25:34.801371: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
I0218 05:25:36.090953 47488301069376 file_utils.py:54] TensorFlow version 2.1.0 available.
I0218 05:25:36.941121 47488301069376 configuration_utils.py:252] loading configuration file ../biobert_data/biobert_v1.1_pubmed/config.json
I0218 05:25:36.941478 47488301069376 configuration_utils.py:290] Model config BertConfig {
  "architectures": null,
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": true,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

I0218 05:25:36.942021 47488301069376 modeling_utils.py:456] loading weights file ../biobert_data/biobert_v1.1_pubmed/model.ckpt.index
I0218 05:25:39.222765 47488301069376 modeling_bert.py:74] Converting TensorFlow checkpoint from /home/aakdemir/biobert_data/biobert_v1.1_pubmed/model.ckpt
I0218 05:25:39.232425 47488301069376 modeling_bert.py:80] Loading TF weight bert/embeddings/LayerNorm/beta with shape [768]
I0218 05:25:39.234950 47488301069376 modeling_bert.py:80] Loading TF weight bert/embeddings/LayerNorm/gamma with shape [768]
I0218 05:25:39.236815 47488301069376 modeling_bert.py:80] Loading TF weight bert/embeddings/position_embeddings with shape [512, 768]
I0218 05:25:39.240006 47488301069376 modeling_bert.py:80] Loading TF weight bert/embeddings/token_type_embeddings with shape [2, 768]
I0218 05:25:39.241779 47488301069376 modeling_bert.py:80] Loading TF weight bert/embeddings/word_embeddings with shape [28996, 768]
I0218 05:25:39.321947 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/beta with shape [768]
I0218 05:25:39.324026 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/gamma with shape [768]
I0218 05:25:39.325873 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/output/dense/bias with shape [768]
I0218 05:25:39.327646 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/output/dense/kernel with shape [768, 768]
I0218 05:25:39.331555 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/self/key/bias with shape [768]
I0218 05:25:39.333727 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/self/key/kernel with shape [768, 768]
I0218 05:25:39.337319 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/self/query/bias with shape [768]
I0218 05:25:39.339129 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/self/query/kernel with shape [768, 768]
I0218 05:25:39.342691 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/self/value/bias with shape [768]
I0218 05:25:39.344438 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/self/value/kernel with shape [768, 768]
I0218 05:25:39.347974 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/intermediate/dense/bias with shape [3072]
I0218 05:25:39.349721 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/intermediate/dense/kernel with shape [768, 3072]
I0218 05:25:39.359742 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/output/LayerNorm/beta with shape [768]
I0218 05:25:39.361678 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/output/LayerNorm/gamma with shape [768]
I0218 05:25:39.363351 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/output/dense/bias with shape [768]
I0218 05:25:39.364994 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/output/dense/kernel with shape [3072, 768]
I0218 05:25:39.374831 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/beta with shape [768]
I0218 05:25:39.376699 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/gamma with shape [768]
I0218 05:25:39.378347 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/output/dense/bias with shape [768]
I0218 05:25:39.379963 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/output/dense/kernel with shape [768, 768]
I0218 05:25:39.382581 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/self/key/bias with shape [768]
I0218 05:25:39.384285 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/self/key/kernel with shape [768, 768]
I0218 05:25:39.386689 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/self/query/bias with shape [768]
I0218 05:25:39.388352 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/self/query/kernel with shape [768, 768]
I0218 05:25:39.390766 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/self/value/bias with shape [768]
I0218 05:25:39.392397 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/self/value/kernel with shape [768, 768]
I0218 05:25:39.395819 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/intermediate/dense/bias with shape [3072]
I0218 05:25:39.397539 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/intermediate/dense/kernel with shape [768, 3072]
I0218 05:25:39.408000 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/output/LayerNorm/beta with shape [768]
I0218 05:25:39.409770 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/output/LayerNorm/gamma with shape [768]
I0218 05:25:39.411363 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/output/dense/bias with shape [768]
I0218 05:25:39.412930 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/output/dense/kernel with shape [3072, 768]
I0218 05:25:39.421052 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/beta with shape [768]
I0218 05:25:39.422838 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/gamma with shape [768]
I0218 05:25:39.424376 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/output/dense/bias with shape [768]
I0218 05:25:39.425907 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/output/dense/kernel with shape [768, 768]
I0218 05:25:39.428395 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/self/key/bias with shape [768]
I0218 05:25:39.429994 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/self/key/kernel with shape [768, 768]
I0218 05:25:39.432283 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/self/query/bias with shape [768]
I0218 05:25:39.433828 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/self/query/kernel with shape [768, 768]
I0218 05:25:39.436105 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/self/value/bias with shape [768]
I0218 05:25:39.437668 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/self/value/kernel with shape [768, 768]
I0218 05:25:39.440018 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/intermediate/dense/bias with shape [3072]
I0218 05:25:39.441555 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/intermediate/dense/kernel with shape [768, 3072]
I0218 05:25:39.451740 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/output/LayerNorm/beta with shape [768]
I0218 05:25:39.453470 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/output/LayerNorm/gamma with shape [768]
I0218 05:25:39.454979 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/output/dense/bias with shape [768]
I0218 05:25:39.456443 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/output/dense/kernel with shape [3072, 768]
I0218 05:25:39.465164 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/beta with shape [768]
I0218 05:25:39.466852 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/gamma with shape [768]
I0218 05:25:39.468380 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/output/dense/bias with shape [768]
I0218 05:25:39.469853 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/output/dense/kernel with shape [768, 768]
I0218 05:25:39.472246 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/self/key/bias with shape [768]
I0218 05:25:39.473798 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/self/key/kernel with shape [768, 768]
I0218 05:25:39.476064 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/self/query/bias with shape [768]
I0218 05:25:39.477612 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/self/query/kernel with shape [768, 768]
I0218 05:25:39.479866 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/self/value/bias with shape [768]
I0218 05:25:39.481371 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/self/value/kernel with shape [768, 768]
I0218 05:25:39.483686 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/intermediate/dense/bias with shape [3072]
I0218 05:25:39.485191 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/intermediate/dense/kernel with shape [768, 3072]
I0218 05:25:39.495455 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/output/LayerNorm/beta with shape [768]
I0218 05:25:39.497136 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/output/LayerNorm/gamma with shape [768]
I0218 05:25:39.498605 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/output/dense/bias with shape [768]
I0218 05:25:39.500050 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/output/dense/kernel with shape [3072, 768]
I0218 05:25:39.508170 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/beta with shape [768]
I0218 05:25:39.509817 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/gamma with shape [768]
I0218 05:25:39.511344 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/output/dense/bias with shape [768]
I0218 05:25:39.512806 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/output/dense/kernel with shape [768, 768]
I0218 05:25:39.515162 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/self/key/bias with shape [768]
I0218 05:25:39.516641 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/self/key/kernel with shape [768, 768]
I0218 05:25:39.518865 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/self/query/bias with shape [768]
I0218 05:25:39.520423 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/self/query/kernel with shape [768, 768]
I0218 05:25:39.522673 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/self/value/bias with shape [768]
I0218 05:25:39.524187 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/self/value/kernel with shape [768, 768]
I0218 05:25:39.526428 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/intermediate/dense/bias with shape [3072]
I0218 05:25:39.527898 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/intermediate/dense/kernel with shape [768, 3072]
I0218 05:25:39.538092 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/output/LayerNorm/beta with shape [768]
I0218 05:25:39.539715 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/output/LayerNorm/gamma with shape [768]
I0218 05:25:39.541126 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/output/dense/bias with shape [768]
I0218 05:25:39.542502 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/output/dense/kernel with shape [3072, 768]
I0218 05:25:39.551173 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/beta with shape [768]
I0218 05:25:39.552785 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/gamma with shape [768]
I0218 05:25:39.554253 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/output/dense/bias with shape [768]
I0218 05:25:39.555645 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/output/dense/kernel with shape [768, 768]
I0218 05:25:39.558063 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/self/key/bias with shape [768]
I0218 05:25:39.559593 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/self/key/kernel with shape [768, 768]
I0218 05:25:39.561852 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/self/query/bias with shape [768]
I0218 05:25:39.563365 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/self/query/kernel with shape [768, 768]
I0218 05:25:39.565605 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/self/value/bias with shape [768]
I0218 05:25:39.567093 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/self/value/kernel with shape [768, 768]
I0218 05:25:39.569299 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/intermediate/dense/bias with shape [3072]
I0218 05:25:39.570784 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/intermediate/dense/kernel with shape [768, 3072]
I0218 05:25:39.581110 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/output/LayerNorm/beta with shape [768]
I0218 05:25:39.582734 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/output/LayerNorm/gamma with shape [768]
I0218 05:25:39.584171 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/output/dense/bias with shape [768]
I0218 05:25:39.585640 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/output/dense/kernel with shape [3072, 768]
I0218 05:25:39.593779 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/beta with shape [768]
I0218 05:25:39.595462 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/gamma with shape [768]
I0218 05:25:39.596922 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/output/dense/bias with shape [768]
I0218 05:25:39.598314 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/output/dense/kernel with shape [768, 768]
I0218 05:25:39.600649 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/self/key/bias with shape [768]
I0218 05:25:39.602138 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/self/key/kernel with shape [768, 768]
I0218 05:25:39.604310 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/self/query/bias with shape [768]
I0218 05:25:39.605756 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/self/query/kernel with shape [768, 768]
I0218 05:25:39.607933 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/self/value/bias with shape [768]
I0218 05:25:39.609358 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/self/value/kernel with shape [768, 768]
I0218 05:25:39.611634 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/intermediate/dense/bias with shape [3072]
I0218 05:25:39.613095 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/intermediate/dense/kernel with shape [768, 3072]
I0218 05:25:39.623208 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/output/LayerNorm/beta with shape [768]
I0218 05:25:39.624789 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/output/LayerNorm/gamma with shape [768]
I0218 05:25:39.626217 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/output/dense/bias with shape [768]
I0218 05:25:39.627581 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/output/dense/kernel with shape [3072, 768]
I0218 05:25:39.636504 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/beta with shape [768]
I0218 05:25:39.638095 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/gamma with shape [768]
I0218 05:25:39.639553 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/output/dense/bias with shape [768]
I0218 05:25:39.640928 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/output/dense/kernel with shape [768, 768]
I0218 05:25:39.643237 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/self/key/bias with shape [768]
I0218 05:25:39.644695 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/self/key/kernel with shape [768, 768]
I0218 05:25:39.646834 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/self/query/bias with shape [768]
I0218 05:25:39.648268 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/self/query/kernel with shape [768, 768]
I0218 05:25:39.650428 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/self/value/bias with shape [768]
I0218 05:25:39.651888 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/self/value/kernel with shape [768, 768]
I0218 05:25:39.654080 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/intermediate/dense/bias with shape [3072]
I0218 05:25:39.655507 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/intermediate/dense/kernel with shape [768, 3072]
I0218 05:25:39.665815 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/output/LayerNorm/beta with shape [768]
I0218 05:25:39.667444 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/output/LayerNorm/gamma with shape [768]
I0218 05:25:39.668846 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/output/dense/bias with shape [768]
I0218 05:25:39.670200 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/output/dense/kernel with shape [3072, 768]
I0218 05:25:39.678366 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/beta with shape [768]
I0218 05:25:39.679949 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/gamma with shape [768]
I0218 05:25:39.681388 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/output/dense/bias with shape [768]
I0218 05:25:39.682739 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/output/dense/kernel with shape [768, 768]
I0218 05:25:39.685034 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/self/key/bias with shape [768]
I0218 05:25:39.686462 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/self/key/kernel with shape [768, 768]
I0218 05:25:39.688574 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/self/query/bias with shape [768]
I0218 05:25:39.690052 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/self/query/kernel with shape [768, 768]
I0218 05:25:39.692239 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/self/value/bias with shape [768]
I0218 05:25:39.693712 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/self/value/kernel with shape [768, 768]
I0218 05:25:39.695923 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/intermediate/dense/bias with shape [3072]
I0218 05:25:39.697331 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/intermediate/dense/kernel with shape [768, 3072]
I0218 05:25:39.707650 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/output/LayerNorm/beta with shape [768]
I0218 05:25:39.709229 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/output/LayerNorm/gamma with shape [768]
I0218 05:25:39.710693 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/output/dense/bias with shape [768]
I0218 05:25:39.712036 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/output/dense/kernel with shape [3072, 768]
I0218 05:25:39.720621 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/beta with shape [768]
I0218 05:25:39.722251 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/gamma with shape [768]
I0218 05:25:39.723633 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/output/dense/bias with shape [768]
I0218 05:25:39.724991 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/output/dense/kernel with shape [768, 768]
I0218 05:25:39.727298 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/self/key/bias with shape [768]
I0218 05:25:39.728735 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/self/key/kernel with shape [768, 768]
I0218 05:25:39.730874 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/self/query/bias with shape [768]
I0218 05:25:39.732282 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/self/query/kernel with shape [768, 768]
I0218 05:25:39.734458 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/self/value/bias with shape [768]
I0218 05:25:39.735847 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/self/value/kernel with shape [768, 768]
I0218 05:25:39.738080 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/intermediate/dense/bias with shape [3072]
I0218 05:25:39.739536 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/intermediate/dense/kernel with shape [768, 3072]
I0218 05:25:39.749821 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/output/LayerNorm/beta with shape [768]
I0218 05:25:39.751423 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/output/LayerNorm/gamma with shape [768]
I0218 05:25:39.752873 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/output/dense/bias with shape [768]
I0218 05:25:39.754210 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/output/dense/kernel with shape [3072, 768]
I0218 05:25:39.762352 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/beta with shape [768]
I0218 05:25:39.763921 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/gamma with shape [768]
I0218 05:25:39.765324 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/output/dense/bias with shape [768]
I0218 05:25:39.766652 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/output/dense/kernel with shape [768, 768]
I0218 05:25:39.768937 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/self/key/bias with shape [768]
I0218 05:25:39.770348 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/self/key/kernel with shape [768, 768]
I0218 05:25:39.772483 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/self/query/bias with shape [768]
I0218 05:25:39.773910 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/self/query/kernel with shape [768, 768]
I0218 05:25:39.776066 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/self/value/bias with shape [768]
I0218 05:25:39.777458 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/self/value/kernel with shape [768, 768]
I0218 05:25:39.779599 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/intermediate/dense/bias with shape [3072]
I0218 05:25:39.781065 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/intermediate/dense/kernel with shape [768, 3072]
I0218 05:25:39.791166 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/output/LayerNorm/beta with shape [768]
I0218 05:25:39.792717 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/output/LayerNorm/gamma with shape [768]
I0218 05:25:39.794096 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/output/dense/bias with shape [768]
I0218 05:25:39.795443 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/output/dense/kernel with shape [3072, 768]
I0218 05:25:39.804161 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/beta with shape [768]
I0218 05:25:39.805730 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/gamma with shape [768]
I0218 05:25:39.807115 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/output/dense/bias with shape [768]
I0218 05:25:39.808453 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/output/dense/kernel with shape [768, 768]
I0218 05:25:39.810754 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/self/key/bias with shape [768]
I0218 05:25:39.812170 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/self/key/kernel with shape [768, 768]
I0218 05:25:39.814289 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/self/query/bias with shape [768]
I0218 05:25:39.815752 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/self/query/kernel with shape [768, 768]
I0218 05:25:39.817877 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/self/value/bias with shape [768]
I0218 05:25:39.819267 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/self/value/kernel with shape [768, 768]
I0218 05:25:39.821523 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/intermediate/dense/bias with shape [3072]
I0218 05:25:39.822917 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/intermediate/dense/kernel with shape [768, 3072]
I0218 05:25:39.833166 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/output/LayerNorm/beta with shape [768]
I0218 05:25:39.834755 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/output/LayerNorm/gamma with shape [768]
I0218 05:25:39.836162 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/output/dense/bias with shape [768]
I0218 05:25:39.837513 47488301069376 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/output/dense/kernel with shape [3072, 768]
I0218 05:25:39.845628 47488301069376 modeling_bert.py:80] Loading TF weight bert/pooler/dense/bias with shape [768]
I0218 05:25:39.847205 47488301069376 modeling_bert.py:80] Loading TF weight bert/pooler/dense/kernel with shape [768, 768]
I0218 05:25:39.850215 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'beta']
I0218 05:25:39.850466 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'gamma']
I0218 05:25:39.850553 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'embeddings', 'position_embeddings']
I0218 05:25:39.850621 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'embeddings', 'token_type_embeddings']
I0218 05:25:39.850684 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'embeddings', 'word_embeddings']
I0218 05:25:39.851204 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:25:39.851336 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:25:39.851439 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'bias']
I0218 05:25:39.851579 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'kernel']
I0218 05:25:39.851670 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'bias']
I0218 05:25:39.851752 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'kernel']
I0218 05:25:39.851829 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'bias']
I0218 05:25:39.851914 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'kernel']
I0218 05:25:39.851992 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'bias']
I0218 05:25:39.852068 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'kernel']
I0218 05:25:39.852148 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'bias']
I0218 05:25:39.852222 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'kernel']
I0218 05:25:39.852402 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'beta']
I0218 05:25:39.852491 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'gamma']
I0218 05:25:39.852567 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'bias']
I0218 05:25:39.852657 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'kernel']
I0218 05:25:39.852965 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:25:39.853063 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:25:39.853142 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'bias']
I0218 05:25:39.853219 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'kernel']
I0218 05:25:39.853297 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'bias']
I0218 05:25:39.853374 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'kernel']
I0218 05:25:39.853447 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'bias']
I0218 05:25:39.853522 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'kernel']
I0218 05:25:39.853595 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'bias']
I0218 05:25:39.853669 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'kernel']
I0218 05:25:39.853748 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'bias']
I0218 05:25:39.853823 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'kernel']
I0218 05:25:39.854002 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'beta']
I0218 05:25:39.854090 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'gamma']
I0218 05:25:39.854165 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'bias']
I0218 05:25:39.854237 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'kernel']
I0218 05:25:39.854516 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:25:39.854609 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:25:39.854686 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'bias']
I0218 05:25:39.854762 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'kernel']
I0218 05:25:39.854838 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'bias']
I0218 05:25:39.854920 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'kernel']
I0218 05:25:39.854996 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'bias']
I0218 05:25:39.855069 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'kernel']
I0218 05:25:39.855143 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'bias']
I0218 05:25:39.855218 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'kernel']
I0218 05:25:39.855304 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'bias']
I0218 05:25:39.855379 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'kernel']
I0218 05:25:39.855654 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'beta']
I0218 05:25:39.855741 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'gamma']
I0218 05:25:39.855816 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'bias']
I0218 05:25:39.855899 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'kernel']
I0218 05:25:39.856067 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:25:39.856154 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:25:39.856229 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'bias']
I0218 05:25:39.856305 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'kernel']
I0218 05:25:39.856381 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'bias']
I0218 05:25:39.856454 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'kernel']
I0218 05:25:39.856529 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'bias']
I0218 05:25:39.856603 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'kernel']
I0218 05:25:39.856675 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'bias']
I0218 05:25:39.856749 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'kernel']
I0218 05:25:39.856821 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'bias']
I0218 05:25:39.856899 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'kernel']
I0218 05:25:39.857170 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'beta']
I0218 05:25:39.857256 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'gamma']
I0218 05:25:39.857331 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'bias']
I0218 05:25:39.857408 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'kernel']
I0218 05:25:39.857583 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:25:39.857671 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:25:39.857748 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'bias']
I0218 05:25:39.857824 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'kernel']
I0218 05:25:39.857912 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'bias']
I0218 05:25:39.858002 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'kernel']
I0218 05:25:39.858078 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'bias']
I0218 05:25:39.858153 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'kernel']
I0218 05:25:39.858227 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'bias']
I0218 05:25:39.858300 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'kernel']
I0218 05:25:39.858378 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'bias']
I0218 05:25:39.858450 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'kernel']
I0218 05:25:39.858621 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'beta']
I0218 05:25:39.858707 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'gamma']
I0218 05:25:39.858781 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'bias']
I0218 05:25:39.858854 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'kernel']
I0218 05:25:39.859149 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:25:39.859240 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:25:39.859316 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'bias']
I0218 05:25:39.859392 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'kernel']
I0218 05:25:39.859472 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'bias']
I0218 05:25:39.859547 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'kernel']
I0218 05:25:39.859621 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'bias']
I0218 05:25:39.859694 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'kernel']
I0218 05:25:39.859767 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'bias']
I0218 05:25:39.859841 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'kernel']
I0218 05:25:39.859923 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'bias']
I0218 05:25:39.859998 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'kernel']
I0218 05:25:39.860167 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'beta']
I0218 05:25:39.860252 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'gamma']
I0218 05:25:39.860325 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'bias']
I0218 05:25:39.860397 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'kernel']
I0218 05:25:39.860699 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:25:39.860792 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:25:39.860868 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'bias']
I0218 05:25:39.860952 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'kernel']
I0218 05:25:39.861030 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'bias']
I0218 05:25:39.861106 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'kernel']
I0218 05:25:39.861180 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'bias']
I0218 05:25:39.861253 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'kernel']
I0218 05:25:39.861327 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'bias']
I0218 05:25:39.861401 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'kernel']
I0218 05:25:39.861477 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'bias']
I0218 05:25:39.861550 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'kernel']
I0218 05:25:39.861719 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'beta']
I0218 05:25:39.861804 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'gamma']
I0218 05:25:39.861877 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'bias']
I0218 05:25:39.861962 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'kernel']
I0218 05:25:39.862258 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:25:39.862349 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:25:39.862426 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'bias']
I0218 05:25:39.862501 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'kernel']
I0218 05:25:39.862581 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'bias']
I0218 05:25:39.862656 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'kernel']
I0218 05:25:39.862731 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'bias']
I0218 05:25:39.862806 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'kernel']
I0218 05:25:39.862885 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'bias']
I0218 05:25:39.862962 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'kernel']
I0218 05:25:39.863050 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'bias']
I0218 05:25:39.863125 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'kernel']
I0218 05:25:39.863295 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'beta']
I0218 05:25:39.863380 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'gamma']
I0218 05:25:39.863454 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'bias']
I0218 05:25:39.863526 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'kernel']
I0218 05:25:39.863821 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:25:39.863920 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:25:39.863999 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'bias']
I0218 05:25:39.864076 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'kernel']
I0218 05:25:39.864154 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'bias']
I0218 05:25:39.864229 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'kernel']
I0218 05:25:39.864304 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'bias']
I0218 05:25:39.864377 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'kernel']
I0218 05:25:39.864451 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'bias']
I0218 05:25:39.864525 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'kernel']
I0218 05:25:39.864600 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'bias']
I0218 05:25:39.864673 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'kernel']
I0218 05:25:39.864842 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'beta']
I0218 05:25:39.864936 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'gamma']
I0218 05:25:39.865011 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'bias']
I0218 05:25:39.865084 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'kernel']
I0218 05:25:39.865262 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:25:39.865350 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:25:39.865426 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'bias']
I0218 05:25:39.865502 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'kernel']
I0218 05:25:39.865580 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'bias']
I0218 05:25:39.865667 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'kernel']
I0218 05:25:39.865743 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'bias']
I0218 05:25:39.865817 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'kernel']
I0218 05:25:39.865897 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'bias']
I0218 05:25:39.865974 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'kernel']
I0218 05:25:39.866050 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'bias']
I0218 05:25:39.866124 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'kernel']
I0218 05:25:39.866400 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'beta']
I0218 05:25:39.866488 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'gamma']
I0218 05:25:39.866563 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'bias']
I0218 05:25:39.866636 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'kernel']
I0218 05:25:39.866816 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:25:39.866908 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:25:39.866985 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'bias']
I0218 05:25:39.867060 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'kernel']
I0218 05:25:39.867136 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'bias']
I0218 05:25:39.867209 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'kernel']
I0218 05:25:39.867283 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'bias']
I0218 05:25:39.867357 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'kernel']
I0218 05:25:39.867431 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'bias']
I0218 05:25:39.867505 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'kernel']
I0218 05:25:39.867579 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'bias']
I0218 05:25:39.867652 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'kernel']
I0218 05:25:39.867938 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'beta']
I0218 05:25:39.868028 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'gamma']
I0218 05:25:39.868103 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'bias']
I0218 05:25:39.868175 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'kernel']
I0218 05:25:39.868361 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:25:39.868451 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:25:39.868527 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'bias']
I0218 05:25:39.868602 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'kernel']
I0218 05:25:39.868682 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'bias']
I0218 05:25:39.868757 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'kernel']
I0218 05:25:39.868832 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'bias']
I0218 05:25:39.868913 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'kernel']
I0218 05:25:39.868989 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'bias']
I0218 05:25:39.869064 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'kernel']
I0218 05:25:39.869136 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'bias']
I0218 05:25:39.869209 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'kernel']
I0218 05:25:39.869478 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'beta']
I0218 05:25:39.869565 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'gamma']
I0218 05:25:39.869640 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'bias']
I0218 05:25:39.869713 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'kernel']
I0218 05:25:39.869874 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'pooler', 'dense', 'bias']
I0218 05:25:39.869958 47488301069376 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'pooler', 'dense', 'kernel']
I0218 05:25:40.641408 47488301069376 tokenization_utils.py:418] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/aakdemir/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
I0218 05:25:40.708817 47488301069376 biomlt.py:513] Model loaded  from: save_dir/pubmedbiobert_init_qasfactoid6b_1802
I0218 05:25:49.299491 47488301069376 biomlt.py:513] Model loaded  from: save_dir/pubmedbiobert_init_qasfactoid6b_1802
I0218 05:25:50.076816 47488301069376 reader.py:439] Loading features from cached file squad_cache/./cached_BioASQ-test-factoid-6b-2-snippet_dev_bert-base-cased_384_0.txt
I0218 05:25:50.089282 47488301069376 biomlt.py:665] Evaluation 0 started
I0218 05:25:50.089441 47488301069376 biomlt.py:666] ***** Running evaluation 2_18_5_25_0 with only_preds = True*****
I0218 05:25:50.089489 47488301069376 biomlt.py:667]   Num examples = 119
I0218 05:25:50.092002 47488301069376 biomlt.py:668]   Batch size = 12
Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]Evaluating:  10%|#         | 1/10 [00:00<00:01,  6.13it/s]Evaluating:  20%|##        | 2/10 [00:00<00:01,  6.62it/s]Evaluating:  30%|###       | 3/10 [00:00<00:00,  7.06it/s]Evaluating:  40%|####      | 4/10 [00:00<00:00,  7.42it/s]Evaluating:  50%|#####     | 5/10 [00:00<00:00,  7.67it/s]Evaluating:  60%|######    | 6/10 [00:00<00:00,  7.90it/s]Evaluating:  70%|#######   | 7/10 [00:00<00:00,  8.09it/s]Evaluating:  80%|########  | 8/10 [00:00<00:00,  8.20it/s]Evaluating:  90%|######### | 9/10 [00:01<00:00,  8.31it/s]Evaluating: 100%|##########| 10/10 [00:01<00:00,  8.58it/s]Evaluating: 100%|##########| 10/10 [00:01<00:00,  8.19it/s]
I0218 05:25:51.315415 47488301069376 squad_metrics.py:392] Writing predictions to: save_dir/predictions_2_18_5_25_0.json
I0218 05:25:51.315604 47488301069376 squad_metrics.py:393] Writing nbest to: biomlt_train_pred_nbest_pred
Picked up JAVA_TOOL_OPTIONS: -XX:+UseSerialGC -Xmx64m -Xms32m
I0218 05:25:57.660669 47161023886400 file_utils.py:38] PyTorch version 1.2.0 available.
2020-02-18 05:25:59.471900: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2020-02-18 05:25:59.472092: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2020-02-18 05:25:59.472113: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
I0218 05:26:00.620089 47161023886400 file_utils.py:54] TensorFlow version 2.1.0 available.
I0218 05:26:01.616041 47161023886400 configuration_utils.py:252] loading configuration file ../biobert_data/biobert_v1.1_pubmed/config.json
I0218 05:26:01.616459 47161023886400 configuration_utils.py:290] Model config BertConfig {
  "architectures": null,
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": true,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

I0218 05:26:01.617146 47161023886400 modeling_utils.py:456] loading weights file ../biobert_data/biobert_v1.1_pubmed/model.ckpt.index
I0218 05:26:03.902198 47161023886400 modeling_bert.py:74] Converting TensorFlow checkpoint from /home/aakdemir/biobert_data/biobert_v1.1_pubmed/model.ckpt
I0218 05:26:03.910971 47161023886400 modeling_bert.py:80] Loading TF weight bert/embeddings/LayerNorm/beta with shape [768]
I0218 05:26:03.913468 47161023886400 modeling_bert.py:80] Loading TF weight bert/embeddings/LayerNorm/gamma with shape [768]
I0218 05:26:03.915333 47161023886400 modeling_bert.py:80] Loading TF weight bert/embeddings/position_embeddings with shape [512, 768]
I0218 05:26:03.918509 47161023886400 modeling_bert.py:80] Loading TF weight bert/embeddings/token_type_embeddings with shape [2, 768]
I0218 05:26:03.920254 47161023886400 modeling_bert.py:80] Loading TF weight bert/embeddings/word_embeddings with shape [28996, 768]
I0218 05:26:04.000016 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:04.002214 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:04.004090 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/output/dense/bias with shape [768]
I0218 05:26:04.005849 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:04.009736 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/self/key/bias with shape [768]
I0218 05:26:04.011977 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/self/key/kernel with shape [768, 768]
I0218 05:26:04.015555 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/self/query/bias with shape [768]
I0218 05:26:04.017325 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/self/query/kernel with shape [768, 768]
I0218 05:26:04.020917 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/self/value/bias with shape [768]
I0218 05:26:04.022645 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/self/value/kernel with shape [768, 768]
I0218 05:26:04.026209 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/intermediate/dense/bias with shape [3072]
I0218 05:26:04.027941 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:04.038037 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/output/LayerNorm/beta with shape [768]
I0218 05:26:04.039995 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/output/LayerNorm/gamma with shape [768]
I0218 05:26:04.041718 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/output/dense/bias with shape [768]
I0218 05:26:04.043359 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/output/dense/kernel with shape [3072, 768]
I0218 05:26:04.053057 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:04.055011 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:04.056705 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/output/dense/bias with shape [768]
I0218 05:26:04.058310 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:04.060842 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/self/key/bias with shape [768]
I0218 05:26:04.062508 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/self/key/kernel with shape [768, 768]
I0218 05:26:04.064845 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/self/query/bias with shape [768]
I0218 05:26:04.066461 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/self/query/kernel with shape [768, 768]
I0218 05:26:04.068786 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/self/value/bias with shape [768]
I0218 05:26:04.070420 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/self/value/kernel with shape [768, 768]
I0218 05:26:04.073160 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/intermediate/dense/bias with shape [3072]
I0218 05:26:04.074862 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:04.084806 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/output/LayerNorm/beta with shape [768]
I0218 05:26:04.086638 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/output/LayerNorm/gamma with shape [768]
I0218 05:26:04.088268 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/output/dense/bias with shape [768]
I0218 05:26:04.089794 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/output/dense/kernel with shape [3072, 768]
I0218 05:26:04.098407 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:04.100229 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:04.101853 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/output/dense/bias with shape [768]
I0218 05:26:04.103360 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:04.105858 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/self/key/bias with shape [768]
I0218 05:26:04.107474 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/self/key/kernel with shape [768, 768]
I0218 05:26:04.109778 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/self/query/bias with shape [768]
I0218 05:26:04.111371 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/self/query/kernel with shape [768, 768]
I0218 05:26:04.113637 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/self/value/bias with shape [768]
I0218 05:26:04.115176 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/self/value/kernel with shape [768, 768]
I0218 05:26:04.117514 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/intermediate/dense/bias with shape [3072]
I0218 05:26:04.119068 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:04.129588 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/output/LayerNorm/beta with shape [768]
I0218 05:26:04.131349 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/output/LayerNorm/gamma with shape [768]
I0218 05:26:04.132921 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/output/dense/bias with shape [768]
I0218 05:26:04.134384 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/output/dense/kernel with shape [3072, 768]
I0218 05:26:04.142085 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:04.143832 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:04.145361 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/output/dense/bias with shape [768]
I0218 05:26:04.146846 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:04.149229 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/self/key/bias with shape [768]
I0218 05:26:04.150762 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/self/key/kernel with shape [768, 768]
I0218 05:26:04.153010 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/self/query/bias with shape [768]
I0218 05:26:04.154505 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/self/query/kernel with shape [768, 768]
I0218 05:26:04.156734 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/self/value/bias with shape [768]
I0218 05:26:04.158191 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/self/value/kernel with shape [768, 768]
I0218 05:26:04.160422 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/intermediate/dense/bias with shape [3072]
I0218 05:26:04.161968 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:04.171917 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/output/LayerNorm/beta with shape [768]
I0218 05:26:04.173743 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/output/LayerNorm/gamma with shape [768]
I0218 05:26:04.175245 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/output/dense/bias with shape [768]
I0218 05:26:04.176681 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/output/dense/kernel with shape [3072, 768]
I0218 05:26:04.185360 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:04.187096 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:04.188614 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/output/dense/bias with shape [768]
I0218 05:26:04.190114 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:04.192579 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/self/key/bias with shape [768]
I0218 05:26:04.194253 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/self/key/kernel with shape [768, 768]
I0218 05:26:04.196530 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/self/query/bias with shape [768]
I0218 05:26:04.198087 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/self/query/kernel with shape [768, 768]
I0218 05:26:04.200312 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/self/value/bias with shape [768]
I0218 05:26:04.201841 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/self/value/kernel with shape [768, 768]
I0218 05:26:04.204070 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/intermediate/dense/bias with shape [3072]
I0218 05:26:04.205524 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:04.215960 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/output/LayerNorm/beta with shape [768]
I0218 05:26:04.217659 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/output/LayerNorm/gamma with shape [768]
I0218 05:26:04.219203 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/output/dense/bias with shape [768]
I0218 05:26:04.220608 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/output/dense/kernel with shape [3072, 768]
I0218 05:26:04.228346 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:04.230103 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:04.231605 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/output/dense/bias with shape [768]
I0218 05:26:04.233097 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:04.235487 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/self/key/bias with shape [768]
I0218 05:26:04.237014 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/self/key/kernel with shape [768, 768]
I0218 05:26:04.239233 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/self/query/bias with shape [768]
I0218 05:26:04.240718 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/self/query/kernel with shape [768, 768]
I0218 05:26:04.242918 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/self/value/bias with shape [768]
I0218 05:26:04.244377 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/self/value/kernel with shape [768, 768]
I0218 05:26:04.246570 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/intermediate/dense/bias with shape [3072]
I0218 05:26:04.248044 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:04.258027 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/output/LayerNorm/beta with shape [768]
I0218 05:26:04.259752 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/output/LayerNorm/gamma with shape [768]
I0218 05:26:04.261255 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/output/dense/bias with shape [768]
I0218 05:26:04.262675 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/output/dense/kernel with shape [3072, 768]
I0218 05:26:04.271276 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:04.272960 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:04.274428 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/output/dense/bias with shape [768]
I0218 05:26:04.275840 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:04.278205 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/self/key/bias with shape [768]
I0218 05:26:04.279702 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/self/key/kernel with shape [768, 768]
I0218 05:26:04.281863 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/self/query/bias with shape [768]
I0218 05:26:04.283307 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/self/query/kernel with shape [768, 768]
I0218 05:26:04.285495 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/self/value/bias with shape [768]
I0218 05:26:04.286996 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/self/value/kernel with shape [768, 768]
I0218 05:26:04.289225 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/intermediate/dense/bias with shape [3072]
I0218 05:26:04.290666 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:04.301239 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/output/LayerNorm/beta with shape [768]
I0218 05:26:04.302942 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/output/LayerNorm/gamma with shape [768]
I0218 05:26:04.304421 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/output/dense/bias with shape [768]
I0218 05:26:04.305814 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/output/dense/kernel with shape [3072, 768]
I0218 05:26:04.313485 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:04.315185 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:04.316734 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/output/dense/bias with shape [768]
I0218 05:26:04.318119 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:04.320432 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/self/key/bias with shape [768]
I0218 05:26:04.321933 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/self/key/kernel with shape [768, 768]
I0218 05:26:04.324073 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/self/query/bias with shape [768]
I0218 05:26:04.325501 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/self/query/kernel with shape [768, 768]
I0218 05:26:04.327677 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/self/value/bias with shape [768]
I0218 05:26:04.329172 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/self/value/kernel with shape [768, 768]
I0218 05:26:04.331412 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/intermediate/dense/bias with shape [3072]
I0218 05:26:04.332844 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:04.342790 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/output/LayerNorm/beta with shape [768]
I0218 05:26:04.344439 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/output/LayerNorm/gamma with shape [768]
I0218 05:26:04.345859 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/output/dense/bias with shape [768]
I0218 05:26:04.347278 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/output/dense/kernel with shape [3072, 768]
I0218 05:26:04.355872 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:04.357509 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:04.358953 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/output/dense/bias with shape [768]
I0218 05:26:04.360365 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:04.362672 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/self/key/bias with shape [768]
I0218 05:26:04.364123 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/self/key/kernel with shape [768, 768]
I0218 05:26:04.366260 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/self/query/bias with shape [768]
I0218 05:26:04.367676 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/self/query/kernel with shape [768, 768]
I0218 05:26:04.369804 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/self/value/bias with shape [768]
I0218 05:26:04.371218 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/self/value/kernel with shape [768, 768]
I0218 05:26:04.373357 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/intermediate/dense/bias with shape [3072]
I0218 05:26:04.374831 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:04.385226 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/output/LayerNorm/beta with shape [768]
I0218 05:26:04.386924 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/output/LayerNorm/gamma with shape [768]
I0218 05:26:04.388379 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/output/dense/bias with shape [768]
I0218 05:26:04.389734 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/output/dense/kernel with shape [3072, 768]
I0218 05:26:04.397342 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:04.399019 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:04.400475 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/output/dense/bias with shape [768]
I0218 05:26:04.401808 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:04.404124 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/self/key/bias with shape [768]
I0218 05:26:04.405558 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/self/key/kernel with shape [768, 768]
I0218 05:26:04.407688 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/self/query/bias with shape [768]
I0218 05:26:04.409090 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/self/query/kernel with shape [768, 768]
I0218 05:26:04.411215 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/self/value/bias with shape [768]
I0218 05:26:04.412595 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/self/value/kernel with shape [768, 768]
I0218 05:26:04.414716 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/intermediate/dense/bias with shape [3072]
I0218 05:26:04.416105 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:04.426144 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/output/LayerNorm/beta with shape [768]
I0218 05:26:04.427764 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/output/LayerNorm/gamma with shape [768]
I0218 05:26:04.429168 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/output/dense/bias with shape [768]
I0218 05:26:04.430503 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/output/dense/kernel with shape [3072, 768]
I0218 05:26:04.439044 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:04.440660 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:04.442082 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/output/dense/bias with shape [768]
I0218 05:26:04.443431 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:04.445762 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/self/key/bias with shape [768]
I0218 05:26:04.447189 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/self/key/kernel with shape [768, 768]
I0218 05:26:04.449284 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/self/query/bias with shape [768]
I0218 05:26:04.450673 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/self/query/kernel with shape [768, 768]
I0218 05:26:04.452837 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/self/value/bias with shape [768]
I0218 05:26:04.454215 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/self/value/kernel with shape [768, 768]
I0218 05:26:04.456444 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/intermediate/dense/bias with shape [3072]
I0218 05:26:04.457826 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:04.468211 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/output/LayerNorm/beta with shape [768]
I0218 05:26:04.469828 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/output/LayerNorm/gamma with shape [768]
I0218 05:26:04.471234 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/output/dense/bias with shape [768]
I0218 05:26:04.472537 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/output/dense/kernel with shape [3072, 768]
I0218 05:26:04.481989 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:04.484235 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:04.485643 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/output/dense/bias with shape [768]
I0218 05:26:04.486985 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:04.489239 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/self/key/bias with shape [768]
I0218 05:26:04.490736 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/self/key/kernel with shape [768, 768]
I0218 05:26:04.492787 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/self/query/bias with shape [768]
I0218 05:26:04.494166 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/self/query/kernel with shape [768, 768]
I0218 05:26:04.496286 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/self/value/bias with shape [768]
I0218 05:26:04.497659 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/self/value/kernel with shape [768, 768]
I0218 05:26:04.499788 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/intermediate/dense/bias with shape [3072]
I0218 05:26:04.501151 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:04.511023 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/output/LayerNorm/beta with shape [768]
I0218 05:26:04.512628 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/output/LayerNorm/gamma with shape [768]
I0218 05:26:04.514053 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/output/dense/bias with shape [768]
I0218 05:26:04.515486 47161023886400 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/output/dense/kernel with shape [3072, 768]
I0218 05:26:04.524055 47161023886400 modeling_bert.py:80] Loading TF weight bert/pooler/dense/bias with shape [768]
I0218 05:26:04.525699 47161023886400 modeling_bert.py:80] Loading TF weight bert/pooler/dense/kernel with shape [768, 768]
I0218 05:26:04.528549 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'beta']
I0218 05:26:04.528835 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'gamma']
I0218 05:26:04.528939 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'embeddings', 'position_embeddings']
I0218 05:26:04.529010 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'embeddings', 'token_type_embeddings']
I0218 05:26:04.529076 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'embeddings', 'word_embeddings']
I0218 05:26:04.529597 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:04.529732 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:04.529829 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'bias']
I0218 05:26:04.529943 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:04.530033 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'bias']
I0218 05:26:04.530135 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'kernel']
I0218 05:26:04.530217 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'bias']
I0218 05:26:04.530295 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'kernel']
I0218 05:26:04.530372 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'bias']
I0218 05:26:04.530447 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'kernel']
I0218 05:26:04.530530 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'bias']
I0218 05:26:04.530604 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'kernel']
I0218 05:26:04.530908 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'beta']
I0218 05:26:04.531005 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'gamma']
I0218 05:26:04.531081 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'bias']
I0218 05:26:04.531156 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'kernel']
I0218 05:26:04.531346 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:04.531438 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:04.531517 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'bias']
I0218 05:26:04.531594 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:04.531672 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'bias']
I0218 05:26:04.531748 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'kernel']
I0218 05:26:04.531823 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'bias']
I0218 05:26:04.531905 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'kernel']
I0218 05:26:04.531982 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'bias']
I0218 05:26:04.532056 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'kernel']
I0218 05:26:04.532135 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'bias']
I0218 05:26:04.532210 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'kernel']
I0218 05:26:04.532501 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'beta']
I0218 05:26:04.532592 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'gamma']
I0218 05:26:04.532669 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'bias']
I0218 05:26:04.532744 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'kernel']
I0218 05:26:04.532954 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:04.533050 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:04.533128 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'bias']
I0218 05:26:04.533205 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:04.533283 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'bias']
I0218 05:26:04.533358 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'kernel']
I0218 05:26:04.533432 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'bias']
I0218 05:26:04.533506 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'kernel']
I0218 05:26:04.533579 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'bias']
I0218 05:26:04.533653 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'kernel']
I0218 05:26:04.533729 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'bias']
I0218 05:26:04.533802 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'kernel']
I0218 05:26:04.533985 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'beta']
I0218 05:26:04.534074 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'gamma']
I0218 05:26:04.534147 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'bias']
I0218 05:26:04.534222 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'kernel']
I0218 05:26:04.534524 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:04.534616 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:04.534694 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'bias']
I0218 05:26:04.534770 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:04.534850 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'bias']
I0218 05:26:04.534932 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'kernel']
I0218 05:26:04.535007 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'bias']
I0218 05:26:04.535081 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'kernel']
I0218 05:26:04.535156 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'bias']
I0218 05:26:04.535229 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'kernel']
I0218 05:26:04.535315 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'bias']
I0218 05:26:04.535391 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'kernel']
I0218 05:26:04.535563 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'beta']
I0218 05:26:04.535648 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'gamma']
I0218 05:26:04.535722 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'bias']
I0218 05:26:04.535798 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'kernel']
I0218 05:26:04.536101 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:04.536194 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:04.536272 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'bias']
I0218 05:26:04.536348 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:04.536430 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'bias']
I0218 05:26:04.536504 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'kernel']
I0218 05:26:04.536579 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'bias']
I0218 05:26:04.536652 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'kernel']
I0218 05:26:04.536725 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'bias']
I0218 05:26:04.536799 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'kernel']
I0218 05:26:04.536877 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'bias']
I0218 05:26:04.536960 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'kernel']
I0218 05:26:04.537243 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'beta']
I0218 05:26:04.537331 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'gamma']
I0218 05:26:04.537406 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'bias']
I0218 05:26:04.537479 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'kernel']
I0218 05:26:04.537666 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:04.537753 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:04.537830 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'bias']
I0218 05:26:04.537915 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:04.537997 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'bias']
I0218 05:26:04.538084 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'kernel']
I0218 05:26:04.538160 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'bias']
I0218 05:26:04.538234 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'kernel']
I0218 05:26:04.538307 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'bias']
I0218 05:26:04.538380 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'kernel']
I0218 05:26:04.538456 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'bias']
I0218 05:26:04.538528 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'kernel']
I0218 05:26:04.538818 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'beta']
I0218 05:26:04.538913 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'gamma']
I0218 05:26:04.538989 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'bias']
I0218 05:26:04.539062 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'kernel']
I0218 05:26:04.539242 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:04.539328 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:04.539404 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'bias']
I0218 05:26:04.539479 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:04.539556 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'bias']
I0218 05:26:04.539631 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'kernel']
I0218 05:26:04.539705 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'bias']
I0218 05:26:04.539779 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'kernel']
I0218 05:26:04.539852 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'bias']
I0218 05:26:04.539934 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'kernel']
I0218 05:26:04.540012 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'bias']
I0218 05:26:04.540085 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'kernel']
I0218 05:26:04.540370 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'beta']
I0218 05:26:04.540457 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'gamma']
I0218 05:26:04.540530 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'bias']
I0218 05:26:04.540603 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'kernel']
I0218 05:26:04.540794 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:04.540894 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:04.540973 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'bias']
I0218 05:26:04.541048 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:04.541127 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'bias']
I0218 05:26:04.541204 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'kernel']
I0218 05:26:04.541279 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'bias']
I0218 05:26:04.541353 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'kernel']
I0218 05:26:04.541426 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'bias']
I0218 05:26:04.541499 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'kernel']
I0218 05:26:04.541574 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'bias']
I0218 05:26:04.541646 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'kernel']
I0218 05:26:04.541942 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'beta']
I0218 05:26:04.542033 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'gamma']
I0218 05:26:04.542107 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'bias']
I0218 05:26:04.542180 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'kernel']
I0218 05:26:04.542359 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:04.542446 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:04.542522 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'bias']
I0218 05:26:04.542597 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:04.542676 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'bias']
I0218 05:26:04.542752 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'kernel']
I0218 05:26:04.542827 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'bias']
I0218 05:26:04.542909 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'kernel']
I0218 05:26:04.542985 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'bias']
I0218 05:26:04.543059 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'kernel']
I0218 05:26:04.543147 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'bias']
I0218 05:26:04.543221 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'kernel']
I0218 05:26:04.543510 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'beta']
I0218 05:26:04.543599 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'gamma']
I0218 05:26:04.543672 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'bias']
I0218 05:26:04.543745 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'kernel']
I0218 05:26:04.543930 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:04.544019 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:04.544095 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'bias']
I0218 05:26:04.544170 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:04.544248 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'bias']
I0218 05:26:04.544323 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'kernel']
I0218 05:26:04.544396 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'bias']
I0218 05:26:04.544470 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'kernel']
I0218 05:26:04.544543 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'bias']
I0218 05:26:04.544616 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'kernel']
I0218 05:26:04.544691 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'bias']
I0218 05:26:04.544764 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'kernel']
I0218 05:26:04.545063 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'beta']
I0218 05:26:04.545154 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'gamma']
I0218 05:26:04.545229 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'bias']
I0218 05:26:04.545303 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'kernel']
I0218 05:26:04.545487 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:04.545576 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:04.545651 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'bias']
I0218 05:26:04.545727 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:04.545802 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'bias']
I0218 05:26:04.545894 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'kernel']
I0218 05:26:04.545972 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'bias']
I0218 05:26:04.546046 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'kernel']
I0218 05:26:04.546120 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'bias']
I0218 05:26:04.546193 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'kernel']
I0218 05:26:04.546268 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'bias']
I0218 05:26:04.546342 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'kernel']
I0218 05:26:04.546622 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'beta']
I0218 05:26:04.546710 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'gamma']
I0218 05:26:04.546784 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'bias']
I0218 05:26:04.546856 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'kernel']
I0218 05:26:04.547047 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:04.547134 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:04.547210 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'bias']
I0218 05:26:04.547285 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:04.547365 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'bias']
I0218 05:26:04.547440 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'kernel']
I0218 05:26:04.547514 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'bias']
I0218 05:26:04.547587 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'kernel']
I0218 05:26:04.547661 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'bias']
I0218 05:26:04.547734 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'kernel']
I0218 05:26:04.547809 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'bias']
I0218 05:26:04.547890 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'kernel']
I0218 05:26:04.548178 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'beta']
I0218 05:26:04.548264 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'gamma']
I0218 05:26:04.548338 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'bias']
I0218 05:26:04.548411 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'kernel']
I0218 05:26:04.548585 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'pooler', 'dense', 'bias']
I0218 05:26:04.548663 47161023886400 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'pooler', 'dense', 'kernel']
I0218 05:26:05.339395 47161023886400 tokenization_utils.py:418] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/aakdemir/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
I0218 05:26:05.406358 47161023886400 biomlt.py:513] Model loaded  from: save_dir/pubmedbiobert_init_qasfactoid6b_1802
I0218 05:26:14.430591 47161023886400 biomlt.py:513] Model loaded  from: save_dir/pubmedbiobert_init_qasfactoid6b_1802
I0218 05:26:15.172383 47161023886400 reader.py:439] Loading features from cached file squad_cache/./cached_BioASQ-test-factoid-6b-3-snippet_dev_bert-base-cased_384_0.txt
I0218 05:26:15.186897 47161023886400 biomlt.py:665] Evaluation 0 started
I0218 05:26:15.187052 47161023886400 biomlt.py:666] ***** Running evaluation 2_18_5_26_0 with only_preds = True*****
I0218 05:26:15.187099 47161023886400 biomlt.py:667]   Num examples = 130
I0218 05:26:15.188249 47161023886400 biomlt.py:668]   Batch size = 12
Evaluating:   0%|          | 0/11 [00:00<?, ?it/s]Evaluating:   9%|9         | 1/11 [00:00<00:01,  6.62it/s]Evaluating:  18%|#8        | 2/11 [00:00<00:01,  7.08it/s]Evaluating:  27%|##7       | 3/11 [00:00<00:01,  7.47it/s]Evaluating:  36%|###6      | 4/11 [00:00<00:00,  7.77it/s]Evaluating:  45%|####5     | 5/11 [00:00<00:00,  7.97it/s]Evaluating:  55%|#####4    | 6/11 [00:00<00:00,  8.14it/s]Evaluating:  64%|######3   | 7/11 [00:00<00:00,  8.24it/s]Evaluating:  73%|#######2  | 8/11 [00:00<00:00,  8.35it/s]Evaluating:  82%|########1 | 9/11 [00:01<00:00,  8.40it/s]Evaluating:  91%|######### | 10/11 [00:01<00:00,  8.45it/s]Evaluating: 100%|##########| 11/11 [00:01<00:00,  8.43it/s]
I0218 05:26:16.494208 47161023886400 squad_metrics.py:392] Writing predictions to: save_dir/predictions_2_18_5_26_0.json
I0218 05:26:16.494510 47161023886400 squad_metrics.py:393] Writing nbest to: biomlt_train_pred_nbest_pred
Picked up JAVA_TOOL_OPTIONS: -XX:+UseSerialGC -Xmx64m -Xms32m
I0218 05:26:22.369914 47235839996992 file_utils.py:38] PyTorch version 1.2.0 available.
2020-02-18 05:26:24.181957: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2020-02-18 05:26:24.182155: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2020-02-18 05:26:24.182177: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
I0218 05:26:25.381084 47235839996992 file_utils.py:54] TensorFlow version 2.1.0 available.
I0218 05:26:26.406146 47235839996992 configuration_utils.py:252] loading configuration file ../biobert_data/biobert_v1.1_pubmed/config.json
I0218 05:26:26.406581 47235839996992 configuration_utils.py:290] Model config BertConfig {
  "architectures": null,
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": true,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

I0218 05:26:26.407260 47235839996992 modeling_utils.py:456] loading weights file ../biobert_data/biobert_v1.1_pubmed/model.ckpt.index
I0218 05:26:28.848334 47235839996992 modeling_bert.py:74] Converting TensorFlow checkpoint from /home/aakdemir/biobert_data/biobert_v1.1_pubmed/model.ckpt
I0218 05:26:28.858671 47235839996992 modeling_bert.py:80] Loading TF weight bert/embeddings/LayerNorm/beta with shape [768]
I0218 05:26:28.861431 47235839996992 modeling_bert.py:80] Loading TF weight bert/embeddings/LayerNorm/gamma with shape [768]
I0218 05:26:28.863379 47235839996992 modeling_bert.py:80] Loading TF weight bert/embeddings/position_embeddings with shape [512, 768]
I0218 05:26:28.866941 47235839996992 modeling_bert.py:80] Loading TF weight bert/embeddings/token_type_embeddings with shape [2, 768]
I0218 05:26:28.868844 47235839996992 modeling_bert.py:80] Loading TF weight bert/embeddings/word_embeddings with shape [28996, 768]
I0218 05:26:28.955238 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:28.957532 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:28.959544 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/output/dense/bias with shape [768]
I0218 05:26:28.961458 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:28.966003 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/self/key/bias with shape [768]
I0218 05:26:28.968519 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/self/key/kernel with shape [768, 768]
I0218 05:26:28.972648 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/self/query/bias with shape [768]
I0218 05:26:28.974605 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/self/query/kernel with shape [768, 768]
I0218 05:26:28.978667 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/self/value/bias with shape [768]
I0218 05:26:28.980582 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/self/value/kernel with shape [768, 768]
I0218 05:26:28.984598 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/intermediate/dense/bias with shape [3072]
I0218 05:26:28.986502 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:28.997605 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/output/LayerNorm/beta with shape [768]
I0218 05:26:28.999705 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/output/LayerNorm/gamma with shape [768]
I0218 05:26:29.001600 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/output/dense/bias with shape [768]
I0218 05:26:29.003412 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/output/dense/kernel with shape [3072, 768]
I0218 05:26:29.014172 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:29.016219 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:29.018063 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/output/dense/bias with shape [768]
I0218 05:26:29.019864 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:29.022679 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/self/key/bias with shape [768]
I0218 05:26:29.024543 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/self/key/kernel with shape [768, 768]
I0218 05:26:29.027162 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/self/query/bias with shape [768]
I0218 05:26:29.028945 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/self/query/kernel with shape [768, 768]
I0218 05:26:29.031567 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/self/value/bias with shape [768]
I0218 05:26:29.033348 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/self/value/kernel with shape [768, 768]
I0218 05:26:29.036458 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/intermediate/dense/bias with shape [3072]
I0218 05:26:29.038324 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:29.048827 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/output/LayerNorm/beta with shape [768]
I0218 05:26:29.050851 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/output/LayerNorm/gamma with shape [768]
I0218 05:26:29.052602 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/output/dense/bias with shape [768]
I0218 05:26:29.054305 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/output/dense/kernel with shape [3072, 768]
I0218 05:26:29.063078 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:29.065057 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:29.066811 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/output/dense/bias with shape [768]
I0218 05:26:29.068486 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:29.071242 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/self/key/bias with shape [768]
I0218 05:26:29.073054 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/self/key/kernel with shape [768, 768]
I0218 05:26:29.075586 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/self/query/bias with shape [768]
I0218 05:26:29.077301 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/self/query/kernel with shape [768, 768]
I0218 05:26:29.079916 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/self/value/bias with shape [768]
I0218 05:26:29.081649 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/self/value/kernel with shape [768, 768]
I0218 05:26:29.084240 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/intermediate/dense/bias with shape [3072]
I0218 05:26:29.085945 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:29.096845 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/output/LayerNorm/beta with shape [768]
I0218 05:26:29.098767 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/output/LayerNorm/gamma with shape [768]
I0218 05:26:29.100533 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/output/dense/bias with shape [768]
I0218 05:26:29.102218 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/output/dense/kernel with shape [3072, 768]
I0218 05:26:29.110776 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:29.112688 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:29.114363 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/output/dense/bias with shape [768]
I0218 05:26:29.115985 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:29.118620 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/self/key/bias with shape [768]
I0218 05:26:29.120317 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/self/key/kernel with shape [768, 768]
I0218 05:26:29.122828 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/self/query/bias with shape [768]
I0218 05:26:29.124498 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/self/query/kernel with shape [768, 768]
I0218 05:26:29.127058 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/self/value/bias with shape [768]
I0218 05:26:29.128736 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/self/value/kernel with shape [768, 768]
I0218 05:26:29.131269 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/intermediate/dense/bias with shape [3072]
I0218 05:26:29.132995 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:29.143455 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/output/LayerNorm/beta with shape [768]
I0218 05:26:29.145338 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/output/LayerNorm/gamma with shape [768]
I0218 05:26:29.146998 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/output/dense/bias with shape [768]
I0218 05:26:29.148588 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/output/dense/kernel with shape [3072, 768]
I0218 05:26:29.157195 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:29.159069 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:29.160702 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/output/dense/bias with shape [768]
I0218 05:26:29.162274 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:29.164877 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/self/key/bias with shape [768]
I0218 05:26:29.166553 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/self/key/kernel with shape [768, 768]
I0218 05:26:29.169010 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/self/query/bias with shape [768]
I0218 05:26:29.170644 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/self/query/kernel with shape [768, 768]
I0218 05:26:29.173092 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/self/value/bias with shape [768]
I0218 05:26:29.174697 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/self/value/kernel with shape [768, 768]
I0218 05:26:29.177158 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/intermediate/dense/bias with shape [3072]
I0218 05:26:29.178786 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:29.189713 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/output/LayerNorm/beta with shape [768]
I0218 05:26:29.191532 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/output/LayerNorm/gamma with shape [768]
I0218 05:26:29.193329 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/output/dense/bias with shape [768]
I0218 05:26:29.195054 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/output/dense/kernel with shape [3072, 768]
I0218 05:26:29.203631 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:29.205586 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:29.207289 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/output/dense/bias with shape [768]
I0218 05:26:29.208925 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:29.211601 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/self/key/bias with shape [768]
I0218 05:26:29.213330 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/self/key/kernel with shape [768, 768]
I0218 05:26:29.215809 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/self/query/bias with shape [768]
I0218 05:26:29.217507 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/self/query/kernel with shape [768, 768]
I0218 05:26:29.220017 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/self/value/bias with shape [768]
I0218 05:26:29.221704 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/self/value/kernel with shape [768, 768]
I0218 05:26:29.224252 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/intermediate/dense/bias with shape [3072]
I0218 05:26:29.225956 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:29.236514 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/output/LayerNorm/beta with shape [768]
I0218 05:26:29.238427 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/output/LayerNorm/gamma with shape [768]
I0218 05:26:29.240114 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/output/dense/bias with shape [768]
I0218 05:26:29.241727 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/output/dense/kernel with shape [3072, 768]
I0218 05:26:29.250391 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:29.252280 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:29.253925 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/output/dense/bias with shape [768]
I0218 05:26:29.255519 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:29.258118 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/self/key/bias with shape [768]
I0218 05:26:29.259798 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/self/key/kernel with shape [768, 768]
I0218 05:26:29.262237 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/self/query/bias with shape [768]
I0218 05:26:29.263903 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/self/query/kernel with shape [768, 768]
I0218 05:26:29.266391 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/self/value/bias with shape [768]
I0218 05:26:29.268064 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/self/value/kernel with shape [768, 768]
I0218 05:26:29.270581 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/intermediate/dense/bias with shape [3072]
I0218 05:26:29.272233 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:29.283048 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/output/LayerNorm/beta with shape [768]
I0218 05:26:29.284929 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/output/LayerNorm/gamma with shape [768]
I0218 05:26:29.286606 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/output/dense/bias with shape [768]
I0218 05:26:29.288224 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/output/dense/kernel with shape [3072, 768]
I0218 05:26:29.296714 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:29.298679 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:29.300356 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/output/dense/bias with shape [768]
I0218 05:26:29.301943 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:29.304558 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/self/key/bias with shape [768]
I0218 05:26:29.306250 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/self/key/kernel with shape [768, 768]
I0218 05:26:29.308782 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/self/query/bias with shape [768]
I0218 05:26:29.310425 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/self/query/kernel with shape [768, 768]
I0218 05:26:29.313000 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/self/value/bias with shape [768]
I0218 05:26:29.314634 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/self/value/kernel with shape [768, 768]
I0218 05:26:29.317168 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/intermediate/dense/bias with shape [3072]
I0218 05:26:29.318796 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:29.329350 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/output/LayerNorm/beta with shape [768]
I0218 05:26:29.331212 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/output/LayerNorm/gamma with shape [768]
I0218 05:26:29.332912 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/output/dense/bias with shape [768]
I0218 05:26:29.334556 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/output/dense/kernel with shape [3072, 768]
I0218 05:26:29.343205 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:29.345100 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:29.346758 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/output/dense/bias with shape [768]
I0218 05:26:29.348389 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:29.351052 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/self/key/bias with shape [768]
I0218 05:26:29.352733 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/self/key/kernel with shape [768, 768]
I0218 05:26:29.355259 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/self/query/bias with shape [768]
I0218 05:26:29.356933 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/self/query/kernel with shape [768, 768]
I0218 05:26:29.359407 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/self/value/bias with shape [768]
I0218 05:26:29.361049 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/self/value/kernel with shape [768, 768]
I0218 05:26:29.363554 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/intermediate/dense/bias with shape [3072]
I0218 05:26:29.365208 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:29.376072 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/output/LayerNorm/beta with shape [768]
I0218 05:26:29.377933 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/output/LayerNorm/gamma with shape [768]
I0218 05:26:29.379573 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/output/dense/bias with shape [768]
I0218 05:26:29.381166 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/output/dense/kernel with shape [3072, 768]
I0218 05:26:29.389622 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:29.391488 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:29.393116 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/output/dense/bias with shape [768]
I0218 05:26:29.394749 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:29.397427 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/self/key/bias with shape [768]
I0218 05:26:29.399211 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/self/key/kernel with shape [768, 768]
I0218 05:26:29.401709 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/self/query/bias with shape [768]
I0218 05:26:29.403313 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/self/query/kernel with shape [768, 768]
I0218 05:26:29.405740 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/self/value/bias with shape [768]
I0218 05:26:29.407355 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/self/value/kernel with shape [768, 768]
I0218 05:26:29.409837 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/intermediate/dense/bias with shape [3072]
I0218 05:26:29.411441 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:29.421876 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/output/LayerNorm/beta with shape [768]
I0218 05:26:29.423743 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/output/LayerNorm/gamma with shape [768]
I0218 05:26:29.425431 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/output/dense/bias with shape [768]
I0218 05:26:29.427113 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/output/dense/kernel with shape [3072, 768]
I0218 05:26:29.435758 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:29.437689 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:29.439346 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/output/dense/bias with shape [768]
I0218 05:26:29.441001 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:29.443599 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/self/key/bias with shape [768]
I0218 05:26:29.445267 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/self/key/kernel with shape [768, 768]
I0218 05:26:29.447678 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/self/query/bias with shape [768]
I0218 05:26:29.449342 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/self/query/kernel with shape [768, 768]
I0218 05:26:29.451817 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/self/value/bias with shape [768]
I0218 05:26:29.453440 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/self/value/kernel with shape [768, 768]
I0218 05:26:29.455939 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/intermediate/dense/bias with shape [3072]
I0218 05:26:29.457600 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:29.468228 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/output/LayerNorm/beta with shape [768]
I0218 05:26:29.470021 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/output/LayerNorm/gamma with shape [768]
I0218 05:26:29.471700 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/output/dense/bias with shape [768]
I0218 05:26:29.473327 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/output/dense/kernel with shape [3072, 768]
I0218 05:26:29.481703 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:29.483606 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:29.485221 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/output/dense/bias with shape [768]
I0218 05:26:29.486762 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:29.489279 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/self/key/bias with shape [768]
I0218 05:26:29.490862 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/self/key/kernel with shape [768, 768]
I0218 05:26:29.493227 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/self/query/bias with shape [768]
I0218 05:26:29.494786 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/self/query/kernel with shape [768, 768]
I0218 05:26:29.497164 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/self/value/bias with shape [768]
I0218 05:26:29.498708 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/self/value/kernel with shape [768, 768]
I0218 05:26:29.501068 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/intermediate/dense/bias with shape [3072]
I0218 05:26:29.502599 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:29.512604 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/output/LayerNorm/beta with shape [768]
I0218 05:26:29.514379 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/output/LayerNorm/gamma with shape [768]
I0218 05:26:29.515892 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/output/dense/bias with shape [768]
I0218 05:26:29.517344 47235839996992 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/output/dense/kernel with shape [3072, 768]
I0218 05:26:29.525337 47235839996992 modeling_bert.py:80] Loading TF weight bert/pooler/dense/bias with shape [768]
I0218 05:26:29.527081 47235839996992 modeling_bert.py:80] Loading TF weight bert/pooler/dense/kernel with shape [768, 768]
I0218 05:26:29.529927 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'beta']
I0218 05:26:29.530187 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'gamma']
I0218 05:26:29.530283 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'embeddings', 'position_embeddings']
I0218 05:26:29.530356 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'embeddings', 'token_type_embeddings']
I0218 05:26:29.530422 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'embeddings', 'word_embeddings']
I0218 05:26:29.530977 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:29.531109 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:29.531214 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'bias']
I0218 05:26:29.531328 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:29.531423 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'bias']
I0218 05:26:29.531507 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'kernel']
I0218 05:26:29.531585 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'bias']
I0218 05:26:29.531662 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'kernel']
I0218 05:26:29.531737 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'bias']
I0218 05:26:29.531814 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'kernel']
I0218 05:26:29.531910 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'bias']
I0218 05:26:29.531993 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'kernel']
I0218 05:26:29.532305 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'beta']
I0218 05:26:29.532404 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'gamma']
I0218 05:26:29.532482 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'bias']
I0218 05:26:29.532557 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'kernel']
I0218 05:26:29.532776 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:29.532871 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:29.532961 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'bias']
I0218 05:26:29.533041 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:29.533125 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'bias']
I0218 05:26:29.533223 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'kernel']
I0218 05:26:29.533301 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'bias']
I0218 05:26:29.533378 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'kernel']
I0218 05:26:29.533452 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'bias']
I0218 05:26:29.533528 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'kernel']
I0218 05:26:29.533616 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'bias']
I0218 05:26:29.533692 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'kernel']
I0218 05:26:29.534004 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'beta']
I0218 05:26:29.534100 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'gamma']
I0218 05:26:29.534183 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'bias']
I0218 05:26:29.534261 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'kernel']
I0218 05:26:29.534440 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:29.534531 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:29.534609 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'bias']
I0218 05:26:29.534687 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:29.534764 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'bias']
I0218 05:26:29.534841 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'kernel']
I0218 05:26:29.534924 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'bias']
I0218 05:26:29.535002 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'kernel']
I0218 05:26:29.535078 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'bias']
I0218 05:26:29.535153 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'kernel']
I0218 05:26:29.535227 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'bias']
I0218 05:26:29.535299 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'kernel']
I0218 05:26:29.535576 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'beta']
I0218 05:26:29.535666 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'gamma']
I0218 05:26:29.535741 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'bias']
I0218 05:26:29.535815 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'kernel']
I0218 05:26:29.536010 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:29.536103 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:29.536180 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'bias']
I0218 05:26:29.536258 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:29.536335 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'bias']
I0218 05:26:29.536412 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'kernel']
I0218 05:26:29.536488 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'bias']
I0218 05:26:29.536563 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'kernel']
I0218 05:26:29.536638 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'bias']
I0218 05:26:29.536712 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'kernel']
I0218 05:26:29.536785 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'bias']
I0218 05:26:29.536863 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'kernel']
I0218 05:26:29.537151 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'beta']
I0218 05:26:29.537240 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'gamma']
I0218 05:26:29.537316 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'bias']
I0218 05:26:29.537390 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'kernel']
I0218 05:26:29.537592 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:29.537683 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:29.537760 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'bias']
I0218 05:26:29.537838 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:29.537935 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'bias']
I0218 05:26:29.538017 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'kernel']
I0218 05:26:29.538093 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'bias']
I0218 05:26:29.538169 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'kernel']
I0218 05:26:29.538244 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'bias']
I0218 05:26:29.538319 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'kernel']
I0218 05:26:29.538418 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'bias']
I0218 05:26:29.538498 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'kernel']
I0218 05:26:29.538804 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'beta']
I0218 05:26:29.538909 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'gamma']
I0218 05:26:29.538987 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'bias']
I0218 05:26:29.539062 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'kernel']
I0218 05:26:29.539265 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:29.539357 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:29.539435 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'bias']
I0218 05:26:29.539511 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:29.539599 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'bias']
I0218 05:26:29.539678 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'kernel']
I0218 05:26:29.539753 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'bias']
I0218 05:26:29.539828 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'kernel']
I0218 05:26:29.539910 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'bias']
I0218 05:26:29.539986 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'kernel']
I0218 05:26:29.540069 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'bias']
I0218 05:26:29.540145 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'kernel']
I0218 05:26:29.540329 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'beta']
I0218 05:26:29.540430 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'gamma']
I0218 05:26:29.540514 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'bias']
I0218 05:26:29.540599 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'kernel']
I0218 05:26:29.540815 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:29.540920 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:29.541002 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'bias']
I0218 05:26:29.541082 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:29.541167 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'bias']
I0218 05:26:29.541260 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'kernel']
I0218 05:26:29.541338 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'bias']
I0218 05:26:29.541414 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'kernel']
I0218 05:26:29.541489 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'bias']
I0218 05:26:29.541564 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'kernel']
I0218 05:26:29.541648 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'bias']
I0218 05:26:29.541724 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'kernel']
I0218 05:26:29.542036 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'beta']
I0218 05:26:29.542131 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'gamma']
I0218 05:26:29.542207 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'bias']
I0218 05:26:29.542281 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'kernel']
I0218 05:26:29.542480 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:29.542573 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:29.542650 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'bias']
I0218 05:26:29.542727 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:29.542821 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'bias']
I0218 05:26:29.542907 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'kernel']
I0218 05:26:29.542985 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'bias']
I0218 05:26:29.543060 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'kernel']
I0218 05:26:29.543134 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'bias']
I0218 05:26:29.543208 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'kernel']
I0218 05:26:29.543290 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'bias']
I0218 05:26:29.543365 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'kernel']
I0218 05:26:29.543658 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'beta']
I0218 05:26:29.543751 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'gamma']
I0218 05:26:29.543826 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'bias']
I0218 05:26:29.543907 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'kernel']
I0218 05:26:29.544122 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:29.544215 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:29.544293 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'bias']
I0218 05:26:29.544370 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:29.544458 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'bias']
I0218 05:26:29.544537 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'kernel']
I0218 05:26:29.544613 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'bias']
I0218 05:26:29.544688 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'kernel']
I0218 05:26:29.544762 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'bias']
I0218 05:26:29.544837 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'kernel']
I0218 05:26:29.544929 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'bias']
I0218 05:26:29.545008 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'kernel']
I0218 05:26:29.545304 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'beta']
I0218 05:26:29.545395 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'gamma']
I0218 05:26:29.545471 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'bias']
I0218 05:26:29.545546 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'kernel']
I0218 05:26:29.545748 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:29.545840 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:29.545925 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'bias']
I0218 05:26:29.546004 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:29.546087 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'bias']
I0218 05:26:29.546166 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'kernel']
I0218 05:26:29.546241 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'bias']
I0218 05:26:29.546317 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'kernel']
I0218 05:26:29.546391 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'bias']
I0218 05:26:29.546467 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'kernel']
I0218 05:26:29.546550 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'bias']
I0218 05:26:29.546642 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'kernel']
I0218 05:26:29.546940 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'beta']
I0218 05:26:29.547034 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'gamma']
I0218 05:26:29.547108 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'bias']
I0218 05:26:29.547182 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'kernel']
I0218 05:26:29.547394 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:29.547486 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:29.547563 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'bias']
I0218 05:26:29.547640 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:29.547716 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'bias']
I0218 05:26:29.547792 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'kernel']
I0218 05:26:29.547867 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'bias']
I0218 05:26:29.547954 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'kernel']
I0218 05:26:29.548029 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'bias']
I0218 05:26:29.548105 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'kernel']
I0218 05:26:29.548185 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'bias']
I0218 05:26:29.548260 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'kernel']
I0218 05:26:29.548549 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'beta']
I0218 05:26:29.548641 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'gamma']
I0218 05:26:29.548716 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'bias']
I0218 05:26:29.548789 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'kernel']
I0218 05:26:29.548992 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:29.549086 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:29.549164 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'bias']
I0218 05:26:29.549241 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:29.549334 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'bias']
I0218 05:26:29.549426 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'kernel']
I0218 05:26:29.549504 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'bias']
I0218 05:26:29.549580 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'kernel']
I0218 05:26:29.549654 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'bias']
I0218 05:26:29.549729 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'kernel']
I0218 05:26:29.549802 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'bias']
I0218 05:26:29.549875 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'kernel']
I0218 05:26:29.550160 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'beta']
I0218 05:26:29.550249 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'gamma']
I0218 05:26:29.550323 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'bias']
I0218 05:26:29.550397 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'kernel']
I0218 05:26:29.550555 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'pooler', 'dense', 'bias']
I0218 05:26:29.550637 47235839996992 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'pooler', 'dense', 'kernel']
I0218 05:26:30.386136 47235839996992 tokenization_utils.py:418] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/aakdemir/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
I0218 05:26:30.453759 47235839996992 biomlt.py:513] Model loaded  from: save_dir/pubmedbiobert_init_qasfactoid6b_1802
I0218 05:26:39.351912 47235839996992 biomlt.py:513] Model loaded  from: save_dir/pubmedbiobert_init_qasfactoid6b_1802
I0218 05:26:40.310589 47235839996992 reader.py:439] Loading features from cached file squad_cache/./cached_BioASQ-test-factoid-6b-4-snippet_dev_bert-base-cased_384_0.txt
I0218 05:26:40.325088 47235839996992 biomlt.py:665] Evaluation 0 started
I0218 05:26:40.325260 47235839996992 biomlt.py:666] ***** Running evaluation 2_18_5_26_0 with only_preds = True*****
I0218 05:26:40.325323 47235839996992 biomlt.py:667]   Num examples = 114
I0218 05:26:40.326896 47235839996992 biomlt.py:668]   Batch size = 12
Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]Evaluating:  10%|#         | 1/10 [00:00<00:01,  5.76it/s]Evaluating:  20%|##        | 2/10 [00:00<00:01,  6.33it/s]Evaluating:  30%|###       | 3/10 [00:00<00:01,  6.84it/s]Evaluating:  40%|####      | 4/10 [00:00<00:00,  7.26it/s]Evaluating:  50%|#####     | 5/10 [00:00<00:00,  7.62it/s]Evaluating:  60%|######    | 6/10 [00:00<00:00,  7.89it/s]Evaluating:  70%|#######   | 7/10 [00:00<00:00,  8.09it/s]Evaluating:  80%|########  | 8/10 [00:00<00:00,  8.23it/s]Evaluating:  90%|######### | 9/10 [00:01<00:00,  8.32it/s]Evaluating: 100%|##########| 10/10 [00:01<00:00,  8.51it/s]
I0218 05:26:41.503068 47235839996992 squad_metrics.py:392] Writing predictions to: save_dir/predictions_2_18_5_26_0.json
I0218 05:26:41.503204 47235839996992 squad_metrics.py:393] Writing nbest to: biomlt_train_pred_nbest_pred
Picked up JAVA_TOOL_OPTIONS: -XX:+UseSerialGC -Xmx64m -Xms32m
I0218 05:26:47.089333 47349935723584 file_utils.py:38] PyTorch version 1.2.0 available.
2020-02-18 05:26:48.908988: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2020-02-18 05:26:48.909207: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2020-02-18 05:26:48.909230: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
I0218 05:26:50.029393 47349935723584 file_utils.py:54] TensorFlow version 2.1.0 available.
I0218 05:26:51.078356 47349935723584 configuration_utils.py:252] loading configuration file ../biobert_data/biobert_v1.1_pubmed/config.json
I0218 05:26:51.078779 47349935723584 configuration_utils.py:290] Model config BertConfig {
  "architectures": null,
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": true,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

I0218 05:26:51.079446 47349935723584 modeling_utils.py:456] loading weights file ../biobert_data/biobert_v1.1_pubmed/model.ckpt.index
I0218 05:26:53.496918 47349935723584 modeling_bert.py:74] Converting TensorFlow checkpoint from /home/aakdemir/biobert_data/biobert_v1.1_pubmed/model.ckpt
I0218 05:26:53.505966 47349935723584 modeling_bert.py:80] Loading TF weight bert/embeddings/LayerNorm/beta with shape [768]
I0218 05:26:53.508528 47349935723584 modeling_bert.py:80] Loading TF weight bert/embeddings/LayerNorm/gamma with shape [768]
I0218 05:26:53.510423 47349935723584 modeling_bert.py:80] Loading TF weight bert/embeddings/position_embeddings with shape [512, 768]
I0218 05:26:53.513591 47349935723584 modeling_bert.py:80] Loading TF weight bert/embeddings/token_type_embeddings with shape [2, 768]
I0218 05:26:53.515378 47349935723584 modeling_bert.py:80] Loading TF weight bert/embeddings/word_embeddings with shape [28996, 768]
I0218 05:26:53.595613 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:53.597811 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:53.599657 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/output/dense/bias with shape [768]
I0218 05:26:53.601404 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:53.605286 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/self/key/bias with shape [768]
I0218 05:26:53.607491 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/self/key/kernel with shape [768, 768]
I0218 05:26:53.611084 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/self/query/bias with shape [768]
I0218 05:26:53.612822 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/self/query/kernel with shape [768, 768]
I0218 05:26:53.616419 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/self/value/bias with shape [768]
I0218 05:26:53.618171 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/attention/self/value/kernel with shape [768, 768]
I0218 05:26:53.621706 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/intermediate/dense/bias with shape [3072]
I0218 05:26:53.623431 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:53.633553 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/output/LayerNorm/beta with shape [768]
I0218 05:26:53.635509 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/output/LayerNorm/gamma with shape [768]
I0218 05:26:53.637220 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/output/dense/bias with shape [768]
I0218 05:26:53.638847 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_0/output/dense/kernel with shape [3072, 768]
I0218 05:26:53.648665 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:53.650566 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:53.652254 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/output/dense/bias with shape [768]
I0218 05:26:53.653846 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:53.656429 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/self/key/bias with shape [768]
I0218 05:26:53.658101 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/self/key/kernel with shape [768, 768]
I0218 05:26:53.660548 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/self/query/bias with shape [768]
I0218 05:26:53.662171 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/self/query/kernel with shape [768, 768]
I0218 05:26:53.664501 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/self/value/bias with shape [768]
I0218 05:26:53.666110 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/attention/self/value/kernel with shape [768, 768]
I0218 05:26:53.669533 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/intermediate/dense/bias with shape [3072]
I0218 05:26:53.671239 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:53.681535 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/output/LayerNorm/beta with shape [768]
I0218 05:26:53.683411 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/output/LayerNorm/gamma with shape [768]
I0218 05:26:53.685017 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/output/dense/bias with shape [768]
I0218 05:26:53.686547 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_1/output/dense/kernel with shape [3072, 768]
I0218 05:26:53.694421 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:53.696237 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:53.697865 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/output/dense/bias with shape [768]
I0218 05:26:53.699400 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:53.701857 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/self/key/bias with shape [768]
I0218 05:26:53.703473 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/self/key/kernel with shape [768, 768]
I0218 05:26:53.705764 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/self/query/bias with shape [768]
I0218 05:26:53.707394 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/self/query/kernel with shape [768, 768]
I0218 05:26:53.709714 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/self/value/bias with shape [768]
I0218 05:26:53.711248 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/attention/self/value/kernel with shape [768, 768]
I0218 05:26:53.713530 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/intermediate/dense/bias with shape [3072]
I0218 05:26:53.715065 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:53.725292 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/output/LayerNorm/beta with shape [768]
I0218 05:26:53.727073 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/output/LayerNorm/gamma with shape [768]
I0218 05:26:53.728584 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/output/dense/bias with shape [768]
I0218 05:26:53.730108 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_10/output/dense/kernel with shape [3072, 768]
I0218 05:26:53.738557 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:53.740294 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:53.741867 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/output/dense/bias with shape [768]
I0218 05:26:53.743398 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:53.745815 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/self/key/bias with shape [768]
I0218 05:26:53.747364 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/self/key/kernel with shape [768, 768]
I0218 05:26:53.749590 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/self/query/bias with shape [768]
I0218 05:26:53.751085 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/self/query/kernel with shape [768, 768]
I0218 05:26:53.753297 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/self/value/bias with shape [768]
I0218 05:26:53.754773 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/attention/self/value/kernel with shape [768, 768]
I0218 05:26:53.757015 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/intermediate/dense/bias with shape [3072]
I0218 05:26:53.758506 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:53.768821 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/output/LayerNorm/beta with shape [768]
I0218 05:26:53.770668 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/output/LayerNorm/gamma with shape [768]
I0218 05:26:53.772257 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/output/dense/bias with shape [768]
I0218 05:26:53.773728 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_11/output/dense/kernel with shape [3072, 768]
I0218 05:26:53.781686 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:53.783464 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:53.785053 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/output/dense/bias with shape [768]
I0218 05:26:53.786509 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:53.788947 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/self/key/bias with shape [768]
I0218 05:26:53.790462 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/self/key/kernel with shape [768, 768]
I0218 05:26:53.792684 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/self/query/bias with shape [768]
I0218 05:26:53.794196 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/self/query/kernel with shape [768, 768]
I0218 05:26:53.796453 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/self/value/bias with shape [768]
I0218 05:26:53.797976 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/attention/self/value/kernel with shape [768, 768]
I0218 05:26:53.800271 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/intermediate/dense/bias with shape [3072]
I0218 05:26:53.801792 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:53.811956 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/output/LayerNorm/beta with shape [768]
I0218 05:26:53.813661 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/output/LayerNorm/gamma with shape [768]
I0218 05:26:53.815175 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/output/dense/bias with shape [768]
I0218 05:26:53.816626 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_2/output/dense/kernel with shape [3072, 768]
I0218 05:26:53.825053 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:53.826734 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:53.828236 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/output/dense/bias with shape [768]
I0218 05:26:53.829646 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:53.831973 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/self/key/bias with shape [768]
I0218 05:26:53.833485 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/self/key/kernel with shape [768, 768]
I0218 05:26:53.835673 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/self/query/bias with shape [768]
I0218 05:26:53.837152 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/self/query/kernel with shape [768, 768]
I0218 05:26:53.839336 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/self/value/bias with shape [768]
I0218 05:26:53.840796 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/attention/self/value/kernel with shape [768, 768]
I0218 05:26:53.842994 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/intermediate/dense/bias with shape [3072]
I0218 05:26:53.844414 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:53.854722 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/output/LayerNorm/beta with shape [768]
I0218 05:26:53.856440 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/output/LayerNorm/gamma with shape [768]
I0218 05:26:53.857996 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/output/dense/bias with shape [768]
I0218 05:26:53.859389 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_3/output/dense/kernel with shape [3072, 768]
I0218 05:26:53.867247 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:53.868997 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:53.870463 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/output/dense/bias with shape [768]
I0218 05:26:53.871867 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:53.874280 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/self/key/bias with shape [768]
I0218 05:26:53.875767 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/self/key/kernel with shape [768, 768]
I0218 05:26:53.877936 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/self/query/bias with shape [768]
I0218 05:26:53.879391 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/self/query/kernel with shape [768, 768]
I0218 05:26:53.881578 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/self/value/bias with shape [768]
I0218 05:26:53.883043 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/attention/self/value/kernel with shape [768, 768]
I0218 05:26:53.885214 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/intermediate/dense/bias with shape [3072]
I0218 05:26:53.886672 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:53.896829 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/output/LayerNorm/beta with shape [768]
I0218 05:26:53.898516 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/output/LayerNorm/gamma with shape [768]
I0218 05:26:53.900032 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/output/dense/bias with shape [768]
I0218 05:26:53.901414 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_4/output/dense/kernel with shape [3072, 768]
I0218 05:26:53.909816 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:53.911467 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:53.912931 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/output/dense/bias with shape [768]
I0218 05:26:53.914302 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:53.916637 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/self/key/bias with shape [768]
I0218 05:26:53.918148 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/self/key/kernel with shape [768, 768]
I0218 05:26:53.920331 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/self/query/bias with shape [768]
I0218 05:26:53.921787 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/self/query/kernel with shape [768, 768]
I0218 05:26:53.923966 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/self/value/bias with shape [768]
I0218 05:26:53.925395 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/attention/self/value/kernel with shape [768, 768]
I0218 05:26:53.927645 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/intermediate/dense/bias with shape [3072]
I0218 05:26:53.929168 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:53.939382 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/output/LayerNorm/beta with shape [768]
I0218 05:26:53.941057 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/output/LayerNorm/gamma with shape [768]
I0218 05:26:53.942538 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/output/dense/bias with shape [768]
I0218 05:26:53.943899 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_5/output/dense/kernel with shape [3072, 768]
I0218 05:26:53.951742 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:53.953423 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:53.954903 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/output/dense/bias with shape [768]
I0218 05:26:53.956267 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:53.958573 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/self/key/bias with shape [768]
I0218 05:26:53.960011 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/self/key/kernel with shape [768, 768]
I0218 05:26:53.962165 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/self/query/bias with shape [768]
I0218 05:26:53.963580 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/self/query/kernel with shape [768, 768]
I0218 05:26:53.965767 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/self/value/bias with shape [768]
I0218 05:26:53.967198 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/attention/self/value/kernel with shape [768, 768]
I0218 05:26:53.969395 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/intermediate/dense/bias with shape [3072]
I0218 05:26:53.970810 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:53.980887 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/output/LayerNorm/beta with shape [768]
I0218 05:26:53.982536 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/output/LayerNorm/gamma with shape [768]
I0218 05:26:53.983990 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/output/dense/bias with shape [768]
I0218 05:26:53.985335 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_6/output/dense/kernel with shape [3072, 768]
I0218 05:26:53.993751 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:53.995434 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:53.996874 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/output/dense/bias with shape [768]
I0218 05:26:53.998222 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:54.000523 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/self/key/bias with shape [768]
I0218 05:26:54.001951 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/self/key/kernel with shape [768, 768]
I0218 05:26:54.004076 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/self/query/bias with shape [768]
I0218 05:26:54.005472 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/self/query/kernel with shape [768, 768]
I0218 05:26:54.007623 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/self/value/bias with shape [768]
I0218 05:26:54.009006 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/attention/self/value/kernel with shape [768, 768]
I0218 05:26:54.011155 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/intermediate/dense/bias with shape [3072]
I0218 05:26:54.012558 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:54.022861 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/output/LayerNorm/beta with shape [768]
I0218 05:26:54.024505 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/output/LayerNorm/gamma with shape [768]
I0218 05:26:54.025908 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/output/dense/bias with shape [768]
I0218 05:26:54.027246 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_7/output/dense/kernel with shape [3072, 768]
I0218 05:26:54.035113 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:54.038198 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:54.041231 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/output/dense/bias with shape [768]
I0218 05:26:54.043953 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:54.048429 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/self/key/bias with shape [768]
I0218 05:26:54.051071 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/self/key/kernel with shape [768, 768]
I0218 05:26:54.055056 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/self/query/bias with shape [768]
I0218 05:26:54.057614 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/self/query/kernel with shape [768, 768]
I0218 05:26:54.061425 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/self/value/bias with shape [768]
I0218 05:26:54.063867 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/attention/self/value/kernel with shape [768, 768]
I0218 05:26:54.067592 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/intermediate/dense/bias with shape [3072]
I0218 05:26:54.069950 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:54.085224 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/output/LayerNorm/beta with shape [768]
I0218 05:26:54.087658 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/output/LayerNorm/gamma with shape [768]
I0218 05:26:54.089875 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/output/dense/bias with shape [768]
I0218 05:26:54.091938 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_8/output/dense/kernel with shape [3072, 768]
I0218 05:26:54.104155 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/beta with shape [768]
I0218 05:26:54.106416 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/gamma with shape [768]
I0218 05:26:54.108449 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/output/dense/bias with shape [768]
I0218 05:26:54.110424 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/output/dense/kernel with shape [768, 768]
I0218 05:26:54.113603 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/self/key/bias with shape [768]
I0218 05:26:54.115645 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/self/key/kernel with shape [768, 768]
I0218 05:26:54.118624 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/self/query/bias with shape [768]
I0218 05:26:54.120634 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/self/query/kernel with shape [768, 768]
I0218 05:26:54.123542 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/self/value/bias with shape [768]
I0218 05:26:54.125444 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/attention/self/value/kernel with shape [768, 768]
I0218 05:26:54.128404 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/intermediate/dense/bias with shape [3072]
I0218 05:26:54.130287 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/intermediate/dense/kernel with shape [768, 3072]
I0218 05:26:54.143064 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/output/LayerNorm/beta with shape [768]
I0218 05:26:54.145050 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/output/LayerNorm/gamma with shape [768]
I0218 05:26:54.146841 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/output/dense/bias with shape [768]
I0218 05:26:54.148599 47349935723584 modeling_bert.py:80] Loading TF weight bert/encoder/layer_9/output/dense/kernel with shape [3072, 768]
I0218 05:26:54.158030 47349935723584 modeling_bert.py:80] Loading TF weight bert/pooler/dense/bias with shape [768]
I0218 05:26:54.160071 47349935723584 modeling_bert.py:80] Loading TF weight bert/pooler/dense/kernel with shape [768, 768]
I0218 05:26:54.163215 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'beta']
I0218 05:26:54.163521 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'gamma']
I0218 05:26:54.163640 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'embeddings', 'position_embeddings']
I0218 05:26:54.163738 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'embeddings', 'token_type_embeddings']
I0218 05:26:54.163831 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'embeddings', 'word_embeddings']
I0218 05:26:54.164596 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:54.164775 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:54.164909 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'bias']
I0218 05:26:54.165048 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:54.165169 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'bias']
I0218 05:26:54.165281 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'kernel']
I0218 05:26:54.165390 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'bias']
I0218 05:26:54.165498 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'kernel']
I0218 05:26:54.165604 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'bias']
I0218 05:26:54.165711 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'kernel']
I0218 05:26:54.165838 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'bias']
I0218 05:26:54.165956 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'kernel']
I0218 05:26:54.166205 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'beta']
I0218 05:26:54.166330 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'gamma']
I0218 05:26:54.166435 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'bias']
I0218 05:26:54.166543 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'kernel']
I0218 05:26:54.166944 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:54.167073 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:54.167191 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'bias']
I0218 05:26:54.167304 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:54.167416 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'bias']
I0218 05:26:54.167526 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'kernel']
I0218 05:26:54.167637 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'bias']
I0218 05:26:54.167747 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'kernel']
I0218 05:26:54.167852 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'bias']
I0218 05:26:54.167973 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'kernel']
I0218 05:26:54.168078 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'bias']
I0218 05:26:54.168182 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'kernel']
I0218 05:26:54.168416 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'beta']
I0218 05:26:54.168534 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'gamma']
I0218 05:26:54.168638 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'bias']
I0218 05:26:54.168742 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'kernel']
I0218 05:26:54.169144 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:54.169272 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:54.169383 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'bias']
I0218 05:26:54.169493 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:54.169601 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'bias']
I0218 05:26:54.169725 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'kernel']
I0218 05:26:54.169834 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'bias']
I0218 05:26:54.169950 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'kernel']
I0218 05:26:54.170059 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'bias']
I0218 05:26:54.170166 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'kernel']
I0218 05:26:54.170270 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'bias']
I0218 05:26:54.170374 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'kernel']
I0218 05:26:54.170605 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'beta']
I0218 05:26:54.170722 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'gamma']
I0218 05:26:54.170825 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'bias']
I0218 05:26:54.170940 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'kernel']
I0218 05:26:54.171337 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:54.171467 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:54.171579 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'bias']
I0218 05:26:54.171689 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:54.171797 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'bias']
I0218 05:26:54.171912 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'kernel']
I0218 05:26:54.172021 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'bias']
I0218 05:26:54.172128 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'kernel']
I0218 05:26:54.172233 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'bias']
I0218 05:26:54.172339 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'kernel']
I0218 05:26:54.172442 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'bias']
I0218 05:26:54.172546 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'kernel']
I0218 05:26:54.172773 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'beta']
I0218 05:26:54.172898 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'gamma']
I0218 05:26:54.173004 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'bias']
I0218 05:26:54.173116 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'kernel']
I0218 05:26:54.173529 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:54.173651 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:54.173757 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'bias']
I0218 05:26:54.173863 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:54.173979 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'bias']
I0218 05:26:54.174083 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'kernel']
I0218 05:26:54.174185 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'bias']
I0218 05:26:54.174287 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'kernel']
I0218 05:26:54.174388 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'bias']
I0218 05:26:54.174493 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'kernel']
I0218 05:26:54.174593 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'bias']
I0218 05:26:54.174692 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'kernel']
I0218 05:26:54.174929 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'beta']
I0218 05:26:54.175047 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'gamma']
I0218 05:26:54.175147 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'bias']
I0218 05:26:54.175247 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'kernel']
I0218 05:26:54.175471 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:54.175586 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:54.175689 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'bias']
I0218 05:26:54.175793 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:54.175905 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'bias']
I0218 05:26:54.176010 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'kernel']
I0218 05:26:54.176112 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'bias']
I0218 05:26:54.176213 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'kernel']
I0218 05:26:54.176313 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'bias']
I0218 05:26:54.176414 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'kernel']
I0218 05:26:54.176512 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'bias']
I0218 05:26:54.176625 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'kernel']
I0218 05:26:54.176851 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'beta']
I0218 05:26:54.176976 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'gamma']
I0218 05:26:54.177078 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'bias']
I0218 05:26:54.177178 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'kernel']
I0218 05:26:54.177556 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:54.177674 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:54.177782 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'bias']
I0218 05:26:54.177894 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:54.178000 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'bias']
I0218 05:26:54.178106 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'kernel']
I0218 05:26:54.178208 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'bias']
I0218 05:26:54.178309 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'kernel']
I0218 05:26:54.178410 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'bias']
I0218 05:26:54.178514 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'kernel']
I0218 05:26:54.178616 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'bias']
I0218 05:26:54.178716 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'kernel']
I0218 05:26:54.178950 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'beta']
I0218 05:26:54.179069 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'gamma']
I0218 05:26:54.179170 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'bias']
I0218 05:26:54.179272 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'kernel']
I0218 05:26:54.179647 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:54.179770 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:54.179876 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'bias']
I0218 05:26:54.179997 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:54.180102 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'bias']
I0218 05:26:54.180207 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'kernel']
I0218 05:26:54.180323 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'bias']
I0218 05:26:54.180427 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'kernel']
I0218 05:26:54.180529 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'bias']
I0218 05:26:54.180630 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'kernel']
I0218 05:26:54.180729 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'bias']
I0218 05:26:54.180827 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'kernel']
I0218 05:26:54.181056 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'beta']
I0218 05:26:54.181170 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'gamma']
I0218 05:26:54.181270 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'bias']
I0218 05:26:54.181375 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'kernel']
I0218 05:26:54.181756 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:54.181874 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:54.181992 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'bias']
I0218 05:26:54.182098 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:54.182202 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'bias']
I0218 05:26:54.182307 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'kernel']
I0218 05:26:54.182409 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'bias']
I0218 05:26:54.182512 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'kernel']
I0218 05:26:54.182614 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'bias']
I0218 05:26:54.182715 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'kernel']
I0218 05:26:54.182816 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'bias']
I0218 05:26:54.182926 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'kernel']
I0218 05:26:54.183157 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'beta']
I0218 05:26:54.183265 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'gamma']
I0218 05:26:54.183360 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'bias']
I0218 05:26:54.183457 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'kernel']
I0218 05:26:54.183840 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:54.183968 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:54.184076 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'bias']
I0218 05:26:54.184178 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:54.184277 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'bias']
I0218 05:26:54.184376 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'kernel']
I0218 05:26:54.184473 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'bias']
I0218 05:26:54.184570 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'kernel']
I0218 05:26:54.184666 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'bias']
I0218 05:26:54.184767 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'kernel']
I0218 05:26:54.184865 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'bias']
I0218 05:26:54.184970 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'kernel']
I0218 05:26:54.185182 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'beta']
I0218 05:26:54.185294 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'gamma']
I0218 05:26:54.185391 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'bias']
I0218 05:26:54.185487 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'kernel']
I0218 05:26:54.185857 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:54.185984 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:54.186087 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'bias']
I0218 05:26:54.186188 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:54.186288 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'bias']
I0218 05:26:54.186386 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'kernel']
I0218 05:26:54.186484 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'bias']
I0218 05:26:54.186585 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'kernel']
I0218 05:26:54.186686 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'bias']
I0218 05:26:54.186784 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'kernel']
I0218 05:26:54.186886 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'bias']
I0218 05:26:54.186998 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'kernel']
I0218 05:26:54.187215 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'beta']
I0218 05:26:54.187323 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'gamma']
I0218 05:26:54.187419 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'bias']
I0218 05:26:54.187515 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'kernel']
I0218 05:26:54.187886 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'beta']
I0218 05:26:54.188004 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'gamma']
I0218 05:26:54.188110 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'bias']
I0218 05:26:54.188212 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'kernel']
I0218 05:26:54.188312 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'bias']
I0218 05:26:54.188410 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'kernel']
I0218 05:26:54.188508 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'bias']
I0218 05:26:54.188610 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'kernel']
I0218 05:26:54.188707 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'bias']
I0218 05:26:54.188805 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'kernel']
I0218 05:26:54.188911 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'bias']
I0218 05:26:54.189008 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'kernel']
I0218 05:26:54.189223 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'beta']
I0218 05:26:54.189331 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'gamma']
I0218 05:26:54.189426 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'bias']
I0218 05:26:54.189522 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'kernel']
I0218 05:26:54.189864 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'pooler', 'dense', 'bias']
I0218 05:26:54.189971 47349935723584 modeling_bert.py:124] Initialize PyTorch weight ['bert', 'pooler', 'dense', 'kernel']
I0218 05:26:54.949725 47349935723584 tokenization_utils.py:418] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/aakdemir/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
I0218 05:26:55.014024 47349935723584 biomlt.py:513] Model loaded  from: save_dir/pubmedbiobert_init_qasfactoid6b_1802
I0218 05:27:03.903462 47349935723584 biomlt.py:513] Model loaded  from: save_dir/pubmedbiobert_init_qasfactoid6b_1802
I0218 05:27:04.645939 47349935723584 reader.py:439] Loading features from cached file squad_cache/./cached_BioASQ-test-factoid-6b-5-snippet_dev_bert-base-cased_384_0.txt
I0218 05:27:04.681167 47349935723584 biomlt.py:665] Evaluation 0 started
I0218 05:27:04.681424 47349935723584 biomlt.py:666] ***** Running evaluation 2_18_5_26_0 with only_preds = True*****
I0218 05:27:04.681542 47349935723584 biomlt.py:667]   Num examples = 183
I0218 05:27:04.683891 47349935723584 biomlt.py:668]   Batch size = 12
Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]Evaluating:   6%|6         | 1/16 [00:00<00:02,  5.01it/s]Evaluating:  12%|#2        | 2/16 [00:00<00:02,  5.71it/s]Evaluating:  19%|#8        | 3/16 [00:00<00:02,  6.33it/s]Evaluating:  25%|##5       | 4/16 [00:00<00:01,  6.87it/s]Evaluating:  31%|###1      | 5/16 [00:00<00:01,  7.31it/s]Evaluating:  38%|###7      | 6/16 [00:00<00:01,  7.63it/s]Evaluating:  44%|####3     | 7/16 [00:00<00:01,  7.87it/s]Evaluating:  50%|#####     | 8/16 [00:01<00:00,  8.03it/s]Evaluating:  56%|#####6    | 9/16 [00:01<00:00,  8.19it/s]Evaluating:  62%|######2   | 10/16 [00:01<00:00,  8.32it/s]Evaluating:  69%|######8   | 11/16 [00:01<00:00,  8.40it/s]Evaluating:  75%|#######5  | 12/16 [00:01<00:00,  8.43it/s]Evaluating:  81%|########1 | 13/16 [00:01<00:00,  8.45it/s]Evaluating:  88%|########7 | 14/16 [00:01<00:00,  8.48it/s]Evaluating:  94%|#########3| 15/16 [00:01<00:00,  8.51it/s]Evaluating: 100%|##########| 16/16 [00:01<00:00,  8.55it/s]
I0218 05:27:06.558254 47349935723584 squad_metrics.py:392] Writing predictions to: save_dir/predictions_2_18_5_26_0.json
I0218 05:27:06.558371 47349935723584 squad_metrics.py:393] Writing nbest to: biomlt_train_pred_nbest_pred
Picked up JAVA_TOOL_OPTIONS: -XX:+UseSerialGC -Xmx64m -Xms32m
