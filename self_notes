When changing the train-dev files make sure to overwrite the cached files!!!
Otherwise the changes are not properly applied

 Initialize model from biobert!!!


Now we have biobert self-fine-tuned on Squad v1.1 
Also fine tune biobert on squad v2.0

Next we need to train the NER head on  some task?? hmm
is it possible to add a new head? Yes, I think so
I think ner head is already included, right?


My models in save_dir


mybiobert_finetunedsquad

mypretrained_finetuned6b_model


===========
FORMULATION FOR YES-NO QUESTIONS
===========

I used a FC layer only on the [CLS] token to get the logits for NO and YES

No class is indexed at 0 and 1 is indexed at 1

Similarly,
During json generation I give as input, No logit as start_logit and Yes logit as end_logit.


