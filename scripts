python run_lm_finetuning.py --train_data_file tests_samples/PMC6961255.txt --output_dir save_dir --model_type bert --mlm --tokenizer_name bert-base-cased --model_name_or_path bert-base-cased



BIOMLT Predict script
python biomlt.py --predict --squad_predict_file ~/biobert_data/datasets/QA/BioASQ/BioASQ-test-factoid-6b-1.json --load_model_path save_dir/qas_2_9_9_50


qsub biomlt_predict_submit.sh save_dir/qas_3_9_11_49 ~/biobert_data/datasets/QA/BioASQ/BioASQ-test-factoid-6b-1.json nbest_out

qsub biomlt_train_predict.sh train_predict_save1 ../biobert_data/datasets/QA/BioASQ/BioASQ-test-factoid-6b-1.json


ToY example scripts!!


!!toy yes-no ( use overwrite_cache and squad_yes_no flags!!)

python biomlt.py --mode joint_flat --squad_train_file toy_yesno.json --init_bert --ner_train_file ent_toy_ner_train.tsv --squad_dir . --batch_size 1 --max_seq_length 20 --squad_predict_file toy_qas.json  --squad_yes_no --overwrite_cache



!!toy train_qas (I would like to try loading model parameters to a larger model)

python biomlt.py --mode qas --squad_train_file toy_qas.json --init_bert--squad_dir . --batch_size 1 --max_seq_length 20 --squad_predict_file toy_qas.json


!! toy train load previous model  ! ! load_all_model works!!

python biomlt.py --mode qas --squad_train_file toy_qas.json --init_bert --squad_dir . --batch_size 1 --max_seq_length 20 --squad_predict_file toy_qas.json  --load_model_path save_dir/qas_2_16_3_42 --load_model

python biomlt.py --mode qas --squad_train_file toy_qas.json  --squad_dir . --batch_size 12  --squad_predict_file toy_qas.json  --init_bert




## Train on 8b test on 7b-trainn

python biomlt_alldata.py --load_model_path key_models/mybiobert_finetunedsquad --model_save_name alldata_8b_0403 --num_train_epochs --squad_train_factoid_file ~/biobert_data/BioASQ-training8b/training8b_squadformat_train_factoid.json --squad_train_list_file ~/biobert_data/BioASQ-training8b/training8b_squadformat_train_list.json --squad_train_yesno_file ~/biobert_data/BioASQ-training8b/training8b_squadformat_train_yesno.json --squad_predict_factoid_file ~/biobert_data/BioASQ-7b/train/Snippet-as-is/train_factoid_7b_snippet.json --squad_predict_list_file ~/biobert_data/BioASQ-7b/train/Snippet-as-is/train_list_7b_snippet.json --squad_predict_yesno_file ~/biobert_data/BioASQ-7b/train/Snippet-as-is/train_yesno_7b_snippet.json --max_seq_length 256

## Train QAS Only with BERT INIT!
python bioMLT/biomlt_alldata.py --init_bert --output_dir qasonly_bertinit_0912  --load_model --max_seq_length 512 --num_train_epochs 10  --batch_size 12

## Train NER onlt with BERT Iniy
python bioMLT/biomlt_alldata.py --init_bert --qas_with_ner --crf --mode ner --total_train_steps 500 --output_dir neronly_initbert_0912_1040  --num_train_epochs 2  --load_model

## Train qas model with a ner head (without joint learning)
python bioMLT/biomlt_alldata.py --mode qas  --num_train_epochs 10 --total_train_steps 1000  --output_dir qasonly_1311_full_test8b --max_seq_length 256 --batch_size 12 --load_model


## Train qas starting with ner model with a ner head of course!
python bioMLT/biomlt_alldata.py --mode qas  --num_train_epochs 2 --total_train_steps 100  --crf --init_ner_head --model_save_name qasmodel1111  --output_dir out1111_loadnerhead  --max_seq_length 256 --batch_size 12 --load_model_path neronly1111_deneme/best_ner_model_on_BC2GM


## Train ner only model with qas head initialized
# Train on combined dataset
python3 bioMLT/biomlt_alldata.py --qas_with_ner --crf --mode ner --total_train_steps 100 --output_dir all-entities_2511_deneme --num_train_epochs 10 --ner_train_file  biobert_data/datasets/NER_for_QAS_combinedonly/All-entities/ent_train.tsv --ner_dev_file  biobert_data/datasets/NER_for_QAS_combinedonly/All-entities/ent_devel.tsv --ner_test_file biobert_data/datasets/NER_for_QAS_combinedonly/All-entities/ent_test.tsv  --load_model


## Qas with ner head input hierarchical
## This code gives the embedding of label predictions of ner to qas component

python bioMLT/biomlt_alldata.py --mode qas  --num_train_epochs 2 --total_train_steps 100  --crf --init_ner_head --model_save_name qasmodel1111  --output_dir out1111_loadnerhead  --max_seq_length 256 --batch_size 12 --load_model_path neronly_stls_0811_folder/best_ner_model_aux__target_BC2GM   --load_ner_label_vocab_path best_ner_model_on_BC2GM_vocab --qas_with_ner

python bioMLT/biomlt_alldata.py --mode qas  --num_train_epochs 2 --total_train_steps 100  --crf --init_ner_head --output_dir out1511_deneme  --max_seq_length 256 --batch_size 12 --load_model_path neronly_outs_1311/best_ner_model_on_BC2GM     --load_ner_label_vocab_path  neronly_outs_1311/best_ner_model_on_BC2GM_vocab --qas_with_ner

python bioMLT/biomlt_alldata.py --mode qas  --num_train_epochs 2 --total_train_steps 100  --crf --init_ner_head --output_dir out_fixner_2612  --max_seq_length 256 --batch_size 12 --load_model_path nerqas_pipeline_1712_1547_5000/best_ner_model_on_All-entities     --load_ner_label_vocab_path  nerqas_pipeline_1712_1547_5000/best_ner_model_on_All-entities_vocab --qas_with_ner



singularity exec --nv ~/singularity/pt-cuda-tf python bioMLT/biomlt_alldata.py --mode qas --output_dir $output_dir  --load_model_path ${load_model_path} --load_ner_label_vocab_path ${load_ner_vocab_path} --max_seq_length 256 --num_train_epochs 30  --qas_with_ner --init_ner_head --crf


# Qas hier all submitter
bash bioMLT/qashier_all_submitter.sh qashier1711_0825 neronly_outs_1311 qashier1711_1


# Qas hier multiple ner folders submitter!

bash bioMLT/qashier_all_multiplefolders_submitter.sh qashier_allsubsets_0212_2021_64dim  biobert_data/datasets/subsetNER_for_QAS_combinedonly  neronly_Alls_2811_   qashier_Alls_0212_64dim
bash bioMLT/qashier_all_multiplefolders_submitter.sh qashier_initberts_1412_2021   biobert_data/datasets/subsetNER_for_QAS_combinedonly  neronly_initbert_allsubsets_0912_1055_   qashier_initberts_1412
bash bioMLT/qashier_all_multiplefolders_submitter.sh qashier_wopenalty_1712   biobert_data/datasets/subsetNER_for_QAS_combinedonly  neronly_wopenalty_1612__   qashier_wopenalty1712



# NER multiple subsets submitter

bash bioMLT/neronly_allsubsets_submitter.sh neronly_Alls_2811 biobert_data/datasets/subsetNER_for_QAS_combinedonly neronly_Alls_2811
bash bioMLT/neronly_allsubsets_submitter.sh neronly_wopenalty_1612 biobert_data/datasets/subsets1612_wopenalty_NER_for_QAS_combinedonly neronly_wopenalty_1612
bash bioMLT/neronly_initbert_allsubsets_submitter.sh neronly_initbert_wopenalty_1712 biobert_data/datasets/subsets1612_wopenalty_NER_for_QAS_combinedonly neronly_initbert_wopenalty_1712_exp




#QAS combine results from subset selection experiments

python  bioMLT/gather_multiple_qashier_results.py  qashier_initberts_1412_2021_
python  bioMLT/gather_multiple_qashier_results.py  qashier_wopenalty_1712_


#NER data seelection
python bioMLT/data_selection.py --ner_root_folder biobert_data/datasets/NER_for_QAS_combinedonly --save_folder_pref subsets1612_0755
qsub bioMLT/subset_generation_submit.sh biobert_data/datasets/NER_for_QAS_combinedonly	subsets_weighted_wopentaly_1712


# NER -> QAS pipeline initbert
bash bioMLT/nerqas_allsubsets_submitter.sh nerqas_pipeline_1712_1547 biobert_data/datasets/subsets1612_wopenalty_NER_for_QAS_combinedonly_  nerqas_pipeline_1712
bash bioMLT/nerqas_allsubsets_submitter.sh nerqas_weighted_initbiobert_1812_1629 biobert_data/datasets/subsets_weighted_wopentaly_1712_NER_for_QAS_combinedonly_ nerqas_weighted_initbiobert_1812_1629

bash bioMLT/nerqas_allsubsets_submitter.sh nerqas_woembed_pipeline_0401 biobert_data/datasets/subsets_weighted_3112_NER_for_QAS_combinedonly_ nerqas_woembed_0401



singularity exec --nv ~/singularity/pt-cuda-tf python bioMLT/biomlt_alldata.py  --qas_with_ner --crf --mode ner --total_train_steps 1000 --output_dir deneme10000  --num_train_epochs 2 --ner_train_file  biobert_data/datasets/subsets_weighted_wopentaly_1712_NER_for_QAS_combinedonly_10000/All-entities/ent_train.tsv  --ner_dev_file biobert_data/datasets/subsets_weighted_wopentaly_1712_NER_for_QAS_combinedonly_10000/All-entities/ent_devel.tsv  --ner_test_file biobert_data/datasets/subsets_weighted_wopentaly_1712_NER_for_QAS_combinedonly_10000/All-entities/ent_test.tsv  --load_model



## CLI qas without ner embedding?!?!?!

python bioMLT/biomlt_alldata.py   --ner_dataset_name All-entities --mode qas --output_dir deneme_0301  --load_model_path singlefolder_3112/best_ner_model_on_All-entities --load_ner_label_vocab_path singlefolder_3112/best_ner_model_on_All-entities_vocab --max_seq_length 256  --init_ner_head --crf --model_save_name best_qas_model_All-entities


# NERQAS single folder pipeline
bash bioMLT/nerqas_singlefolder_submitter.sh singlefolder_3112 biobert_data/datasets/NER_for_QAS_combinedonly  singlefolder_3112_exp


## Run NER 15 February 2021

# BC5CDR-disease
python biomlt_alldata.py --qas_with_ner --crf --mode ner --total_train_steps 1000 --output_dir ../trial_2402  --num_train_epochs 10 --ner_train_file  ../biobert_data/datasets/NER/BC5CDR-disease/ent_train.tsv  --ner_dev_file ../biobert_data/datasets/NER/BC5CDR-disease/ent_devel.tsv  --ner_test_file ../biobert_data/datasets/NER/BC5CDR-disease/ent_test.tsv  --load_model

# JNLPBA
python biomlt_alldata.py --qas_with_ner --crf --mode ner --total_train_steps 1000 --output_dir ../trial_1502_2021  --num_train_epochs 10 --ner_train_file  ../biobert_data/datasets/NER/JNLPBA/ent_train.tsv  --ner_dev_file ../biobert_data/datasets/NER/JNLPBA/ent_devel.tsv  --ner_test_file ../biobert_data/datasets/NER/JNLPBA/ent_test.tsv  --load_model



## Run QAS with NER 1502 2021
python bioMLT/biomlt_alldata.py    --qas_with_ner --crf  --ner_dataset_name BC5CDR-chem --mode qas --output_dir qaswithner_2202  --load_model_path trial_1502_2021/best_ner_model_on_BC5CDR-chem --load_ner_label_vocab_path trial_1502_2021/best_ner_model_on_BC5CDR-chem_vocab --max_seq_length 256 --init_ner_head --crf --model_save_name best_qas_model_BC5CDR-chem
